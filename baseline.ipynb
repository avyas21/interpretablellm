{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f343ad35-e195-4859-a3a7-35e4120d1b69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f343ad35-e195-4859-a3a7-35e4120d1b69",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "9e6c1b75-186a-488c-8da6-481994247d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "# !pip install transformers\n",
        "# !pip install numpy==1.26.0\n",
        "# !pip install tensorflow[and-cuda]\n",
        "# !pip install torch torchvision torchaudio\n",
        "# !pip install --upgrade ipywidgets\n",
        "# !pip install tf-keras\n",
        "# !pip install pandas\n",
        "# !pip install scikit-learn\n",
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2962b9d0-ba93-4ffa-bf14-18aa63fedea6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2962b9d0-ba93-4ffa-bf14-18aa63fedea6",
        "outputId": "4a55f024-ade7-45e5-d11c-17c1d48f07ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Mar  8 23:20:27 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/avyas21/interpretablellm.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-j8_3zq1UT6",
        "outputId": "ca126bd9-519a-40ff-ec60-597ac9485bb9"
      },
      "id": "n-j8_3zq1UT6",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'interpretablellm' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd interpretablellm\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srClFliF1d4O",
        "outputId": "7d397ce7-f8e3-455a-f8fb-47c5e2f47594"
      },
      "id": "srClFliF1d4O",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/interpretablellm\n",
            "baseline.ipynb\tbaseline_prompt.txt  data  README.md  setup_dataset.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b82dd9f-e6d6-46ac-9843-ca25199683dc",
      "metadata": {
        "id": "9b82dd9f-e6d6-46ac-9843-ca25199683dc"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4d09ed15-aedc-4fc2-818f-a72d9d98c52f",
      "metadata": {
        "id": "4d09ed15-aedc-4fc2-818f-a72d9d98c52f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b76f9c22-366a-4a15-a179-4c5383ebc244",
      "metadata": {
        "id": "b76f9c22-366a-4a15-a179-4c5383ebc244"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"data/train_data.csv\")\n",
        "test_data = pd.read_csv(\"data/test_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "42f93876-e2bf-4b48-b96e-49f03c8593b2",
      "metadata": {
        "id": "42f93876-e2bf-4b48-b96e-49f03c8593b2"
      },
      "outputs": [],
      "source": [
        "POSITIVE_WORDS = [\"positive\", \"great\", \"good\", \"happy\", \"amazing\", \"fantastic\", \"yes\"]\n",
        "NEGATIVE_WORDS = [\"negative\", \"bad\", \"sad\", \"terrible\", \"horrible\", \"no\", \"critical\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "48213dc3-68d1-4b8b-a454-ec5deed1ee28",
      "metadata": {
        "id": "48213dc3-68d1-4b8b-a454-ec5deed1ee28"
      },
      "outputs": [],
      "source": [
        "def convert_lbl_to_int(label):\n",
        "    if label.lower() in POSITIVE_WORDS:\n",
        "        return 1\n",
        "    if label.lower() in NEGATIVE_WORDS:\n",
        "        return 0\n",
        "    return -1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c594c372-0387-4956-b9e6-a362de13ab1b",
      "metadata": {
        "id": "c594c372-0387-4956-b9e6-a362de13ab1b"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dcc1073e-f664-4053-a2a0-6a866a8ba2b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcc1073e-f664-4053-a2a0-6a866a8ba2b0",
        "outputId": "efa189f4-ca05-4498-d010-ec08c5704317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n",
        "from transformers import BertModel, BertTokenizer, BertForSequenceClassification, BertConfig\n",
        "from transformers import pipeline\n",
        "from sklearn.metrics import f1_score\n",
        "from torchinfo import summary\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "04d9d4b2-68ac-433e-933f-407c97a5807b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04d9d4b2-68ac-433e-933f-407c97a5807b",
        "outputId": "c724af15-1a80-4995-90ce-b4a06ebd6f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given a book review, classify it as expressing a positive or negative sentiment.\n",
            "Review: Test Prompt\n",
            "This review is either positive or negative sentiment. If one had to chosen, the sentiment in the review is [MASK].\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def get_prompt(review):\n",
        "  with open(\"baseline_prompt.txt\", \"r\") as file:\n",
        "    prompt = file.read()\n",
        "  prompt = prompt.replace(\"<REVIEW>\", review)\n",
        "  return prompt\n",
        "\n",
        "print(get_prompt(\"Test Prompt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "943dccdc-d64d-438c-8285-42ae4cac65aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "943dccdc-d64d-438c-8285-42ae4cac65aa",
        "outputId": "f2a130f2-89d2-40dc-f20b-400799bd5af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Load the BERT model and tokenizer\n",
        "baseline_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "baseline_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "baseline_unmasker = pipeline('fill-mask', model='bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "36e84017-3c95-4195-a64e-872de86aa27d",
      "metadata": {
        "id": "36e84017-3c95-4195-a64e-872de86aa27d"
      },
      "outputs": [],
      "source": [
        "def predict(review, unmasker):\n",
        "  prompt = get_prompt(review)\n",
        "  predictions = unmasker(prompt)\n",
        "  valid_predictions = POSITIVE_WORDS + NEGATIVE_WORDS\n",
        "\n",
        "  for prediction in predictions:\n",
        "    if(prediction['token_str'] in valid_predictions):\n",
        "      return prediction['token_str']\n",
        "\n",
        "  for prediction in predictions:\n",
        "    print(prediction['token_str'])\n",
        "\n",
        "  sentiment = [\"positive\", \"negative\"]\n",
        "  #If not found, lets predict random\n",
        "  return \"NOT FOUND\" #random.choice(sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3efd9030-e3ac-4c20-92b5-a82df8b63a4b",
      "metadata": {
        "id": "3efd9030-e3ac-4c20-92b5-a82df8b63a4b"
      },
      "outputs": [],
      "source": [
        "def predict_baseline(df, model, tokenizer, unmasker):\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    for idx, row in df.iterrows():\n",
        "        input_text = row['Review']\n",
        "        prediction = predict(input_text, unmasker)\n",
        "        predictions.append(convert_lbl_to_int(prediction))\n",
        "        labels.append(convert_lbl_to_int(row['Sentiment']))\n",
        "    return predictions, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9DhDookCV4cA",
      "metadata": {
        "id": "9DhDookCV4cA"
      },
      "outputs": [],
      "source": [
        "def score_baseline(baseline_model, df, baseline_tokenizer, baseline_unmasker):\n",
        "    predictions, labels = predict_baseline(df, baseline_model, baseline_tokenizer, baseline_unmasker)\n",
        "    values, counts = np.unique(np.array(predictions), return_counts=True)\n",
        "\n",
        "    for v, c in zip(values, counts):\n",
        "        print(f\"Value: {v}, Count: {c}\")\n",
        "\n",
        "    return f1_score(labels, predictions, average='micro')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "85f05cf6-0511-4f27-90fc-207b5e4678ef",
      "metadata": {
        "id": "85f05cf6-0511-4f27-90fc-207b5e4678ef",
        "outputId": "8cbdabe4-2067-43f6-de42-bd3f11e58c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3fd9da737e0a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_baseline_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_unmasker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_baseline_f1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-85bf27f5dc6a>\u001b[0m in \u001b[0;36mscore_baseline\u001b[0;34m(baseline_model, df, baseline_tokenizer, baseline_unmasker)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_unmasker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_unmasker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-b781ced9ccdb>\u001b[0m in \u001b[0;36mpredict_baseline\u001b[0;34m(df, model, tokenizer, unmasker)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munmasker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_lbl_to_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_lbl_to_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-92679eb72f8e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(review, unmasker)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munmasker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munmasker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mvalid_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOSITIVE_WORDS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mNEGATIVE_WORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtoken_str\u001b[0m\u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto\u001b[0m \u001b[0mreplace\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \"\"\"\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1360\u001b[0m             )\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1462\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    586\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 515\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# If this is instantiated as a cross-attention module, the keys and values come from an encoder; the attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m     \u001b[0;31m# fmt: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1740\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1741\u001b[0m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_baseline_f1 = score_baseline(baseline_model, train_data, baseline_tokenizer, baseline_unmasker)\n",
        "print(train_baseline_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0f61be6-17ee-42cd-ab37-024e26f63319",
      "metadata": {
        "id": "d0f61be6-17ee-42cd-ab37-024e26f63319"
      },
      "outputs": [],
      "source": [
        "test_baseline_f1 = score_baseline(baseline_model, test_data, baseline_tokenizer, baseline_unmasker)\n",
        "print(test_baseline_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89b6d9a2-b1cc-438c-bdf2-7cddba7ce1a7",
      "metadata": {
        "id": "89b6d9a2-b1cc-438c-bdf2-7cddba7ce1a7"
      },
      "source": [
        "## Probe Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "hs9tJr6xUte3",
      "metadata": {
        "id": "hs9tJr6xUte3"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from transformers import AutoTokenizer, BertModel\n",
        "import pandas as pd\n",
        "\n",
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self, n, randomized=False, linear_1 = None, linear_2 = None):\n",
        "        super(CustomBERTModel, self).__init__()\n",
        "        if randomized:\n",
        "          config = BertConfig()\n",
        "          self.bert = BertModel(config).to(torch.device(\"cuda\"))\n",
        "        else:\n",
        "          self.bert=  BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.bert.encoder.layer = nn.ModuleList(self.bert.encoder.layer[:n])\n",
        "\n",
        "        # Reinitialize weights for each layer in the encoder\n",
        "        for layer in self.bert.encoder.layer:\n",
        "            for module in layer.modules():\n",
        "              for mod in module.modules():\n",
        "                  if isinstance(mod, (nn.Linear, nn.Conv2d)):\n",
        "                      # Reinitialize weights for linear and convolution layers\n",
        "                      # print(\"Before Randomization:\", mod.weight)\n",
        "                      nn.init.xavier_uniform_(mod.weight)\n",
        "                      # print(\"After Randomization:\", mod.weight)\n",
        "                      if mod.bias is not None:\n",
        "                          nn.init.zeros_(mod.bias)\n",
        "                  elif isinstance(mod, nn.LayerNorm):\n",
        "                      # Reinitialize LayerNorm layers\n",
        "                      nn.init.ones_(mod.weight)\n",
        "                      nn.init.zeros_(mod.bias)\n",
        "                  # print(\"Mod\")\n",
        "                  # print(mod)\n",
        "              #print(module)\n",
        "            #print(layer)\n",
        "\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        ### New layers:\n",
        "\n",
        "        if linear_1 is not None:\n",
        "          self.linear_1 = linear_1\n",
        "        else:\n",
        "          self.linear_1 = nn.Linear(768, 256)\n",
        "\n",
        "        if linear_2 is not None:\n",
        "          self.linear_2 = linear_2\n",
        "        else:\n",
        "          self.linear_2 = nn.Linear(256, 1)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "        output = self.bert(input_ids=ids, attention_mask=mask, output_hidden_states=True)\n",
        "\n",
        "        linear1_output = self.linear_1(output.last_hidden_state[:,0,:])\n",
        "        linear2_output = self.linear_2(self.dropout(linear1_output))\n",
        "        sigmoid_output = self.sigmoid(linear2_output)\n",
        "        return sigmoid_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6a62027a-0f6f-4059-a36d-51ef161bfdc8",
      "metadata": {
        "id": "6a62027a-0f6f-4059-a36d-51ef161bfdc8"
      },
      "outputs": [],
      "source": [
        "def get_custom_bert_model(num_bert_layers, toggle):\n",
        "  gpu_available = torch.cuda.is_available()\n",
        "  model = CustomBERTModel(num_bert_layers, toggle)\n",
        "  if gpu_available:\n",
        "    return model.to(torch.device(\"cuda\"))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3c3e9cee-6067-4933-ab0a-2a8de05ccc0b",
      "metadata": {
        "id": "3c3e9cee-6067-4933-ab0a-2a8de05ccc0b"
      },
      "outputs": [],
      "source": [
        "baseline_model = get_custom_bert_model(2, True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(baseline_model.linear_1)"
      ],
      "metadata": {
        "id": "_Qf2h0cuD_gl",
        "outputId": "3f7aa949-0bde-4946-b870-b8ddee6e1f28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_Qf2h0cuD_gl",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=768, out_features=256, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "ZuLuCEEqWxpF",
      "metadata": {
        "id": "ZuLuCEEqWxpF"
      },
      "outputs": [],
      "source": [
        "def get_inputs_labels(df):\n",
        "    inputs = []\n",
        "    labels = []\n",
        "    for idx, row in train_data.iterrows():\n",
        "        input_text = row['Review']\n",
        "        inputs.append(input_text)\n",
        "        labels.append(1 if row['Sentiment'] == 'positive' else 0)\n",
        "    return inputs, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "485XykGLie_x",
      "metadata": {
        "id": "485XykGLie_x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "L53zFoGWaT0q",
      "metadata": {
        "id": "L53zFoGWaT0q"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "inputs, labels = get_inputs_labels(train_data)\n",
        "dataset = TextDataset(inputs, labels, tokenizer, 512)\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "qVWM7p9W7FkT",
      "metadata": {
        "id": "qVWM7p9W7FkT"
      },
      "outputs": [],
      "source": [
        "def predict(model, df):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    gpu_available = torch.cuda.is_available()\n",
        "    with torch.no_grad():\n",
        "        for idx, row in df.iterrows():\n",
        "            input_text = row['Review']\n",
        "            encoding = tokenizer(input_text, add_special_tokens=True, max_length = 512, padding='max_length', truncation=True, return_tensors='pt')\n",
        "            if gpu_available:\n",
        "              input_ids = encoding['input_ids'].cuda()\n",
        "              attention_mask = encoding['attention_mask'].cuda()\n",
        "              prediction = model(encoding['input_ids'].cuda(), encoding['attention_mask'].cuda())\n",
        "            else:\n",
        "              input_ids = encoding['input_ids']\n",
        "              attention_mask = encoding['attention_mask']\n",
        "              prediction = model(encoding['input_ids'], encoding['attention_mask'])\n",
        "            predictions.append(1 if prediction > 0.5 else 0)\n",
        "            labels.append(convert_lbl_to_int(row['Sentiment']))\n",
        "\n",
        "    return predictions, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "151ed761-27be-4990-942f-841d0b741037",
      "metadata": {
        "id": "151ed761-27be-4990-942f-841d0b741037"
      },
      "outputs": [],
      "source": [
        "def score_model(model, train_df, test_df):\n",
        "    train_f1 = None\n",
        "    test_f1 = None\n",
        "\n",
        "    if train_df is not None:\n",
        "        train_predictions, train_labels = predict(model, train_df)\n",
        "        train_f1 = f1_score(train_labels, train_predictions, average='micro')\n",
        "\n",
        "    if test_df is not None:\n",
        "        test_predictions, test_labels = predict(model, test_df)\n",
        "        test_f1 = f1_score(test_labels, test_predictions, average='micro')\n",
        "\n",
        "    return train_f1, test_f1\n",
        "\n",
        "# print(score_custom_model(model, train_data, test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "6a39bd50-3426-4627-8071-f22a47a73545",
      "metadata": {
        "id": "6a39bd50-3426-4627-8071-f22a47a73545"
      },
      "outputs": [],
      "source": [
        "def get_loss(model, df):\n",
        "    inputs, labels = get_inputs_labels(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGn4ZHtQ3Xum",
        "outputId": "1947567e-d367-4eb6-c3b3-d4bd769a9738"
      },
      "id": "ZGn4ZHtQ3Xum",
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "q9hGOXhcfrs4",
      "metadata": {
        "id": "q9hGOXhcfrs4"
      },
      "outputs": [],
      "source": [
        "def train_model(model, epochs, dataloader, train_df, learning_rate = 1e-3, calc_train_f1 = True):\n",
        "    criterion = nn.BCELoss() ## If required define your own criterion\n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = learning_rate)\n",
        "    gpu_available = torch.cuda.is_available()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        i = 0\n",
        "        for batch in dataloader:\n",
        "            targets = np.array(batch['label'])\n",
        "            targets = torch.tensor(np.expand_dims(targets,axis=1)).float()\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch['input_ids']\n",
        "            attention_mask = batch['attention_mask']\n",
        "\n",
        "            if gpu_available:\n",
        "              targets = targets.cuda()\n",
        "              input_ids = input_ids.cuda()\n",
        "              attention_mask = attention_mask.cuda()\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            # if i % 20 == 0:\n",
        "            #   print(loss)\n",
        "            optimizer.step()\n",
        "            i += 1\n",
        "\n",
        "        if calc_train_f1:\n",
        "          train_f1, _ = score_model(model, train_df, None)\n",
        "          print(\"Epoch: \" + str(epoch) + \" F1: \" + str(train_f1) + \" LOSS: \" + str(loss))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(baseline_model, 10, dataloader, train_data)"
      ],
      "metadata": {
        "id": "AcswQWUFrPEW",
        "outputId": "b663958a-4480-4bd5-a153-8cfb0391fe16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AcswQWUFrPEW",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7615, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.9821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6292, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6782, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7056, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6367, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7618, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7097, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6708, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6675, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5491, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6323, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 0 F1: 0.64725 LOSS: tensor(0.7356, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5937, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6100, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6302, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6193, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5501, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6210, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6340, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6194, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7346, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6282, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6512, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5590, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.6475 LOSS: tensor(0.6097, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5724, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6352, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5158, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6631, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5549, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5652, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6317, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5312, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6029, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5604, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5621, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.70175 LOSS: tensor(0.5253, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6251, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5578, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6108, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6028, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5694, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6714, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5595, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6511, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6397, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5969, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6477, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5796, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5345, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.7225 LOSS: tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5643, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5733, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5995, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4362, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5557, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6412, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5232, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5604, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5726, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6226, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5406, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.73 LOSS: tensor(0.5446, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7115, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5503, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4513, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5661, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6075, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4966, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6707, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5487, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6975, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5202, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6646, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7503, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4964, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.669125 LOSS: tensor(0.5960, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5745, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6063, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6676, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6498, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6353, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5150, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5432, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7459, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4675, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5175, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4788, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5446, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.731625 LOSS: tensor(0.5298, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5747, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5049, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5710, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5629, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5107, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4334, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5205, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4137, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6231, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6998, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5248, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6979, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.638 LOSS: tensor(0.7044, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6087, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7730, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5389, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5646, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4802, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5816, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5557, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6173, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6102, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5373, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6615, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.754 LOSS: tensor(0.5724, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5564, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5651, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5373, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5174, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4987, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4422, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5045, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6247, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5480, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5251, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5343, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5457, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.650375 LOSS: tensor(0.5714, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, test_f1 = score_model(baseline_model, None, test_data)\n",
        "print(\"TEST F1: \" + str(test_f1))"
      ],
      "metadata": {
        "id": "QLqEBas5Af88",
        "outputId": "d3a20986-b09b-4c71-d501-9a00eb1f4b29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QLqEBas5Af88",
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST F1: 0.6005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_all_randomized_models(dataloader, train_df, test_df, epochs, max_n, learning_rate = 1e-3):\n",
        "    model_scores = []\n",
        "    for n in range(1,max_n + 1):\n",
        "        print(\"N: \" + str(n))\n",
        "        model = get_custom_bert_model(n, True)\n",
        "        train_model(model, epochs, dataloader, train_df, learning_rate)\n",
        "        _, test_f1 = score_model(model, None, test_df)\n",
        "        print(\"TEST F1: \" + str(test_f1))\n",
        "        model_scores.append([n, test_f1])\n",
        "\n",
        "    return model_scores"
      ],
      "metadata": {
        "id": "q8q83o7zBZly"
      },
      "id": "q8q83o7zBZly",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a1949ee-a200-460d-a868-68e3a313b19e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a1949ee-a200-460d-a868-68e3a313b19e",
        "outputId": "e3fe799c-9294-4100-841a-e878ac141319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N: 1\n",
            "Epoch: 0 F1: 0.618875 LOSS: tensor(0.6379, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-134-70b63bbe3862>\", line 1, in <cell line: 0>\n",
            "    model_scores = score_all_randomized_models(dataloader, train_data, test_data, 10, 12)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-130-bc5c5454ae21>\", line 6, in score_all_randomized_models\n",
            "    train_model(model, epochs, dataloader, train_df, learning_rate)\n",
            "  File \"<ipython-input-133-fd5dc9de79d6>\", line 29, in train_model\n",
            "    train_f1, _ = score_model(model, train_df, None)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-126-c3b53445eb9a>\", line 6, in score_model\n",
            "    train_predictions, train_labels = predict(model, train_df)\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-125-392c8d43dee1>\", line 9, in predict\n",
            "    encoding = tokenizer(input_text, add_special_tokens=True, max_length = 512, padding='max_length', truncation=True, return_tensors='pt')\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2868, in __call__\n",
            "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2978, in _call_one\n",
            "    return self.encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3054, in encode_plus\n",
            "    return self._encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 801, in _encode_plus\n",
            "    first_ids = get_input_ids(text)\n",
            "                ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 768, in get_input_ids\n",
            "    tokens = self.tokenize(text, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 662, in tokenize\n",
            "    tokens = self.tokens_trie.split(text)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line None, in split\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-134-70b63bbe3862>\", line 1, in <cell line: 0>\n",
            "    model_scores = score_all_randomized_models(dataloader, train_data, test_data, 10, 12)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-130-bc5c5454ae21>\", line 6, in score_all_randomized_models\n",
            "    train_model(model, epochs, dataloader, train_df, learning_rate)\n",
            "  File \"<ipython-input-133-fd5dc9de79d6>\", line 29, in train_model\n",
            "    train_f1, _ = score_model(model, train_df, None)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-126-c3b53445eb9a>\", line 6, in score_model\n",
            "    train_predictions, train_labels = predict(model, train_df)\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-125-392c8d43dee1>\", line 9, in predict\n",
            "    encoding = tokenizer(input_text, add_special_tokens=True, max_length = 512, padding='max_length', truncation=True, return_tensors='pt')\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2868, in __call__\n",
            "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2978, in _call_one\n",
            "    return self.encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3054, in encode_plus\n",
            "    return self._encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 801, in _encode_plus\n",
            "    first_ids = get_input_ids(text)\n",
            "                ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 768, in get_input_ids\n",
            "    tokens = self.tokenize(text, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 662, in tokenize\n",
            "    tokens = self.tokens_trie.split(text)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line None, in split\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-134-70b63bbe3862>\", line 1, in <cell line: 0>\n",
            "    model_scores = score_all_randomized_models(dataloader, train_data, test_data, 10, 12)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-130-bc5c5454ae21>\", line 6, in score_all_randomized_models\n",
            "    train_model(model, epochs, dataloader, train_df, learning_rate)\n",
            "  File \"<ipython-input-133-fd5dc9de79d6>\", line 29, in train_model\n",
            "    train_f1, _ = score_model(model, train_df, None)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-126-c3b53445eb9a>\", line 6, in score_model\n",
            "    train_predictions, train_labels = predict(model, train_df)\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-125-392c8d43dee1>\", line 9, in predict\n",
            "    encoding = tokenizer(input_text, add_special_tokens=True, max_length = 512, padding='max_length', truncation=True, return_tensors='pt')\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2868, in __call__\n",
            "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2978, in _call_one\n",
            "    return self.encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3054, in encode_plus\n",
            "    return self._encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 801, in _encode_plus\n",
            "    first_ids = get_input_ids(text)\n",
            "                ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 768, in get_input_ids\n",
            "    tokens = self.tokenize(text, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 662, in tokenize\n",
            "    tokens = self.tokens_trie.split(text)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line None, in split\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n"
          ]
        }
      ],
      "source": [
        "model_scores = score_all_randomized_models(dataloader, train_data, test_data, 10, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5bb3b666-1ec1-41f8-b58f-ae6d265b533a",
      "metadata": {
        "id": "5bb3b666-1ec1-41f8-b58f-ae6d265b533a"
      },
      "outputs": [],
      "source": [
        "def score_all_probe_models(dataloader, train_df, test_df, epochs, max_n, learning_rate = 1e-3):\n",
        "    model_scores = []\n",
        "    for n in range(1,max_n + 1):\n",
        "        print(\"N: \" + str(n))\n",
        "        model = get_custom_bert_model(n)\n",
        "        train_model(model, epochs, dataloader, train_df, learning_rate)\n",
        "        _, test_f1 = score_model(model, None, test_df)\n",
        "        print(\"TEST F1: \" + str(test_f1))\n",
        "        model_scores.append([n, test_f1])\n",
        "\n",
        "    return model_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scalar Mixing Weights"
      ],
      "metadata": {
        "id": "8lTdl-n_zyXY"
      },
      "id": "8lTdl-n_zyXY"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from transformers import AutoTokenizer, BertModel\n",
        "import pandas as pd\n",
        "\n",
        "class ScalarMixingWeightModel(nn.Module):\n",
        "    def __init__(self, n, i):\n",
        "        super(ScalarMixingWeightModel, self).__init__()\n",
        "\n",
        "        self.bert= BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.bert.encoder.layer = nn.ModuleList(self.bert.encoder.layer[:n])\n",
        "        self.n = n\n",
        "        self.layer_weights = nn.Parameter(torch.ones(self.n))\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "        self.i = i\n",
        "\n",
        "        self.gamma = nn.Parameter(torch.ones(1))\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        ### New layers:\n",
        "        if self.i == 1:\n",
        "          self.linear1 = nn.Linear(768, 1)\n",
        "        elif self.i == 2:\n",
        "          self.linear1 = nn.Linear(768, 384)\n",
        "          self.linear2 = nn.Linear(384, 1)\n",
        "        elif self.i == 3:\n",
        "          self.linear1 = nn.Linear(768, 384)\n",
        "          self.linear2 = nn.Linear(384, 192)\n",
        "          self.linear3 = nn.Linear(192, 1)\n",
        "        elif self.i == 4:\n",
        "          self.linear1 = nn.Linear(768, 384)\n",
        "          self.linear2 = nn.Linear(384, 192)\n",
        "          self.linear3 = nn.Linear(192, 96)\n",
        "          self.linear4 = nn.Linear(96, 1)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "        outputs = self.bert(input_ids=ids, attention_mask=mask, output_hidden_states=True)\n",
        "\n",
        "        hidden_states = outputs.hidden_states[1:1 + self.n]\n",
        "\n",
        "        normalized_weights = self.softmax(self.layer_weights)\n",
        "        scalar_mixing_weight = self.gamma * sum(normalized_weights[i] * hidden_states[i] for i in range(self.n))\n",
        "\n",
        "        if self.i == 1:\n",
        "          linear1_output = self.dropout(self.linear1(scalar_mixing_weight[:, 0, :]))\n",
        "          sigmoid_output = self.sigmoid(linear1_output)\n",
        "        elif self.i == 2:\n",
        "          linear1_output = self.linear1(scalar_mixing_weight[:, 0, :])\n",
        "          linear2_output = self.linear2(self.dropout(linear1_output))\n",
        "          sigmoid_output = self.sigmoid(linear2_output)\n",
        "        elif self.i == 3:\n",
        "          linear1_output = self.linear1(scalar_mixing_weight[:, 0, :])\n",
        "          linear2_output = self.linear2(self.dropout(linear1_output))\n",
        "          linear3_output = self.linear3(self.dropout(linear2_output))\n",
        "          sigmoid_output = self.sigmoid(linear3_output)\n",
        "        elif self.i == 4:\n",
        "          linear1_output = self.linear1(scalar_mixing_weight[:, 0, :])\n",
        "          linear2_output = self.linear2(self.dropout(linear1_output))\n",
        "          linear3_output = self.linear3(self.dropout(linear2_output))\n",
        "          linear4_output = self.linear4(self.dropout(linear3_output))\n",
        "          sigmoid_output = self.sigmoid(linear4_output)\n",
        "\n",
        "        return sigmoid_output\n"
      ],
      "metadata": {
        "id": "Ltfx0_XMzxeh"
      },
      "id": "Ltfx0_XMzxeh",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scalar_mixing_model(num_bert_layers, i):\n",
        "  gpu_available = torch.cuda.is_available()\n",
        "  model = ScalarMixingWeightModel(num_bert_layers, i)\n",
        "\n",
        "  if gpu_available:\n",
        "    return model.to(torch.device(\"cuda\"))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "lGp5exkZ17M_"
      },
      "id": "lGp5exkZ17M_",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = {}\n",
        "for i in range(11,13):\n",
        "  test_scalar = get_scalar_mixing_model(i,1)\n",
        "  train_model(test_scalar, 10, dataloader, train_data, learning_rate = 0.1)\n",
        "  print(i, \":\", test_scalar.layer_weights)\n",
        "  weights[i] = test_scalar.layer_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "uhSJ9GBk1__M",
        "outputId": "3d119c8a-606a-49af-da0b-06a974d1058b",
        "collapsed": true
      },
      "id": "uhSJ9GBk1__M",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(19.0966, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(37.8466, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(12.8466, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(22.2649, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(34.7649, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(15.9716, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(12.9332, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(19.1399, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(28.4716, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(19.0749, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(19.1182, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(19.0749, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 0 F1: 0.5 LOSS: tensor(37.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(59.3750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(56.2500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-1ee9f25a95ea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtest_scalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scalar_mixing_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_scalar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_scalar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_scalar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-f45f65e4e4ba>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, epochs, dataloader, train_df, learning_rate, calc_train_f1)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[1;32m    522\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     def backward(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disable_current_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0mguard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DisableFuncTorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    623\u001b[0m                         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    355\u001b[0m         )\n\u001b[1;32m    356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             nonzero_finite_vals = torch.masked_select(\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lrs = [0.1, 0.01, 0.001, 0.0001]\n",
        "for lr in lrs:\n",
        "  for i in range(1,5):\n",
        "    test_scalar = get_scalar_mixing_model(2, i)\n",
        "    train_model(test_scalar, 10, dataloader, train_data, learning_rate = lr)\n",
        "    print(\"Learning rate:\", lr, \"Number of layers\", i)"
      ],
      "metadata": {
        "id": "GsEo-F0ghfj8",
        "outputId": "d2ba4cea-9109-49e9-b76e-e43b8ad87fd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GsEo-F0ghfj8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 F1: 0.5 LOSS: tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.579 LOSS: tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.747375 LOSS: tensor(0.6665, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.76175 LOSS: tensor(0.4873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.754875 LOSS: tensor(0.4700, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.771375 LOSS: tensor(0.3286, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.817375 LOSS: tensor(0.4258, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.808375 LOSS: tensor(0.3882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.7935 LOSS: tensor(0.6432, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.827375 LOSS: tensor(0.3705, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.1 Number of layers 1\n",
            "Epoch: 0 F1: 0.5 LOSS: tensor(51.5625, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.5 LOSS: tensor(62.5000, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.5 LOSS: tensor(56.2500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.1 Number of layers 2\n",
            "Epoch: 0 F1: 0.5 LOSS: tensor(32.8125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.5 LOSS: tensor(56.2500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.5 LOSS: tensor(42.1875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.5 LOSS: tensor(57.8125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.5 LOSS: tensor(42.1875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.1 Number of layers 3\n",
            "Epoch: 0 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.5 LOSS: tensor(51.5625, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.5 LOSS: tensor(39.0625, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.1 Number of layers 4\n",
            "Epoch: 0 F1: 0.688625 LOSS: tensor(0.6729, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.72625 LOSS: tensor(0.5735, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.7225 LOSS: tensor(0.4890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.778 LOSS: tensor(0.4555, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.797125 LOSS: tensor(0.4818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.766375 LOSS: tensor(0.5095, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.81625 LOSS: tensor(0.3692, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.81525 LOSS: tensor(0.4498, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.823 LOSS: tensor(0.3185, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.8255 LOSS: tensor(0.4187, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.01 Number of layers 1\n",
            "Epoch: 0 F1: 0.623625 LOSS: tensor(0.5963, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.755375 LOSS: tensor(0.5610, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.773625 LOSS: tensor(0.4210, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.8115 LOSS: tensor(0.4335, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.80525 LOSS: tensor(0.3416, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.8125 LOSS: tensor(0.4147, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.8195 LOSS: tensor(0.4914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.80625 LOSS: tensor(0.4377, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.719 LOSS: tensor(0.3938, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.80725 LOSS: tensor(0.3015, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.01 Number of layers 2\n",
            "Epoch: 0 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.5 LOSS: tensor(59.3750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.5 LOSS: tensor(43.7500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.5 LOSS: tensor(57.8125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.5 LOSS: tensor(65.6250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.01 Number of layers 3\n",
            "Epoch: 0 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.5 LOSS: tensor(43.7500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.01 Number of layers 4\n",
            "Epoch: 0 F1: 0.622875 LOSS: tensor(0.7243, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.637875 LOSS: tensor(0.6641, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.644875 LOSS: tensor(0.6571, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.66575 LOSS: tensor(0.6701, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.6845 LOSS: tensor(0.6082, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.693125 LOSS: tensor(0.5579, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.714375 LOSS: tensor(0.5850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.734625 LOSS: tensor(0.5675, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.728 LOSS: tensor(0.5235, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.75325 LOSS: tensor(0.5115, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.001 Number of layers 1\n",
            "Epoch: 0 F1: 0.67325 LOSS: tensor(0.6584, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.710625 LOSS: tensor(0.5366, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.751375 LOSS: tensor(0.5209, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.786125 LOSS: tensor(0.4284, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.800375 LOSS: tensor(0.5209, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.7775 LOSS: tensor(0.3774, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.783625 LOSS: tensor(0.4044, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.814875 LOSS: tensor(0.4114, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.784625 LOSS: tensor(0.3569, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.82025 LOSS: tensor(0.4046, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.001 Number of layers 2\n",
            "Epoch: 0 F1: 0.643875 LOSS: tensor(0.6335, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.6025 LOSS: tensor(0.6195, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.75075 LOSS: tensor(0.4377, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.792625 LOSS: tensor(0.3910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.7925 LOSS: tensor(0.3448, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.81275 LOSS: tensor(0.4162, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.81725 LOSS: tensor(0.4785, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.81775 LOSS: tensor(0.5427, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.816375 LOSS: tensor(0.4804, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.74775 LOSS: tensor(0.4635, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.001 Number of layers 3\n",
            "Epoch: 0 F1: 0.599375 LOSS: tensor(0.6650, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.7395 LOSS: tensor(0.5235, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.78475 LOSS: tensor(0.4132, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.763875 LOSS: tensor(0.4276, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.80175 LOSS: tensor(0.4442, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.71925 LOSS: tensor(0.4258, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.8145 LOSS: tensor(0.5349, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.82225 LOSS: tensor(0.5277, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.812875 LOSS: tensor(0.4315, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.813375 LOSS: tensor(0.3786, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.001 Number of layers 4\n",
            "Epoch: 0 F1: 0.499625 LOSS: tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.583 LOSS: tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.57775 LOSS: tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.5655 LOSS: tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.61075 LOSS: tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.609375 LOSS: tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.61575 LOSS: tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.619625 LOSS: tensor(0.6795, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.623875 LOSS: tensor(0.6763, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.626625 LOSS: tensor(0.6737, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.0001 Number of layers 1\n",
            "Epoch: 0 F1: 0.62725 LOSS: tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.63025 LOSS: tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.656 LOSS: tensor(0.6105, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.665125 LOSS: tensor(0.6588, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.691 LOSS: tensor(0.5975, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.70775 LOSS: tensor(0.5938, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.708 LOSS: tensor(0.6180, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.735 LOSS: tensor(0.5417, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.740875 LOSS: tensor(0.5361, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.755125 LOSS: tensor(0.4723, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.0001 Number of layers 2\n",
            "Epoch: 0 F1: 0.62875 LOSS: tensor(0.6600, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.626875 LOSS: tensor(0.6630, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.647125 LOSS: tensor(0.6467, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.678625 LOSS: tensor(0.5910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.71625 LOSS: tensor(0.5632, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.71625 LOSS: tensor(0.4906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.766125 LOSS: tensor(0.4897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.747 LOSS: tensor(0.3912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.754 LOSS: tensor(0.5500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.774375 LOSS: tensor(0.5170, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.0001 Number of layers 3\n",
            "Epoch: 0 F1: 0.519125 LOSS: tensor(0.6764, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.60725 LOSS: tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.645125 LOSS: tensor(0.6653, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.6925 LOSS: tensor(0.5769, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.747625 LOSS: tensor(0.4810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.74725 LOSS: tensor(0.4977, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.77625 LOSS: tensor(0.4830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.789 LOSS: tensor(0.4862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.79275 LOSS: tensor(0.5131, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.799625 LOSS: tensor(0.4610, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.0001 Number of layers 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40f8f63b-329d-4066-b72b-2354e3efc9e2",
      "metadata": {
        "id": "40f8f63b-329d-4066-b72b-2354e3efc9e2"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c1b985c-3ce7-41f2-90cb-a4a8059794d6",
      "metadata": {
        "id": "2c1b985c-3ce7-41f2-90cb-a4a8059794d6",
        "outputId": "94e5ebe3-9b8b-4fbe-fb8b-718d9d38212d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "================================================================================\n",
              "Layer (type:depth-idx)                                  Param #\n",
              "================================================================================\n",
              "BertModel                                               --\n",
              "├─BertEmbeddings: 1-1                                   --\n",
              "│    └─Embedding: 2-1                                   (23,440,896)\n",
              "│    └─Embedding: 2-2                                   (393,216)\n",
              "│    └─Embedding: 2-3                                   (1,536)\n",
              "│    └─LayerNorm: 2-4                                   (1,536)\n",
              "│    └─Dropout: 2-5                                     --\n",
              "├─BertEncoder: 1-2                                      --\n",
              "│    └─ModuleList: 2-6                                  --\n",
              "│    │    └─BertLayer: 3-1                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-2                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-3                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-4                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-5                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-6                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-7                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-8                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-9                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-10                             (7,087,872)\n",
              "│    │    └─BertLayer: 3-11                             7,087,872\n",
              "│    │    └─BertLayer: 3-12                             7,087,872\n",
              "├─BertPooler: 1-3                                       --\n",
              "│    └─Linear: 2-7                                      590,592\n",
              "│    └─Tanh: 2-8                                        --\n",
              "================================================================================\n",
              "Total params: 109,482,240\n",
              "Trainable params: 14,766,336\n",
              "Non-trainable params: 94,715,904\n",
              "================================================================================"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(baseline_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c58c62b-6c11-4810-bd52-b3d58aa7f853",
      "metadata": {
        "id": "0c58c62b-6c11-4810-bd52-b3d58aa7f853",
        "outputId": "30c9add2-5227-4935-942a-1a5d847cac67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "===========================================================================\n",
              "Layer (type:depth-idx)                             Param #\n",
              "===========================================================================\n",
              "CustomBERTModel                                    --\n",
              "├─BertEmbeddings: 1-1                              --\n",
              "│    └─Embedding: 2-1                              (23,440,896)\n",
              "│    └─Embedding: 2-2                              (393,216)\n",
              "│    └─Embedding: 2-3                              (1,536)\n",
              "│    └─LayerNorm: 2-4                              (1,536)\n",
              "│    └─Dropout: 2-5                                --\n",
              "├─ModuleList: 1-2                                  --\n",
              "│    └─BertLayer: 2-6                              --\n",
              "│    │    └─BertAttention: 3-1                     (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-2                  (2,362,368)\n",
              "│    │    └─BertOutput: 3-3                        (2,361,600)\n",
              "│    └─BertLayer: 2-7                              --\n",
              "│    │    └─BertAttention: 3-4                     (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-5                  (2,362,368)\n",
              "│    │    └─BertOutput: 3-6                        (2,361,600)\n",
              "│    └─BertLayer: 2-8                              --\n",
              "│    │    └─BertAttention: 3-7                     (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-8                  (2,362,368)\n",
              "│    │    └─BertOutput: 3-9                        (2,361,600)\n",
              "│    └─BertLayer: 2-9                              --\n",
              "│    │    └─BertAttention: 3-10                    (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-11                 (2,362,368)\n",
              "│    │    └─BertOutput: 3-12                       (2,361,600)\n",
              "│    └─BertLayer: 2-10                             --\n",
              "│    │    └─BertAttention: 3-13                    (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-14                 (2,362,368)\n",
              "│    │    └─BertOutput: 3-15                       (2,361,600)\n",
              "│    └─BertLayer: 2-11                             --\n",
              "│    │    └─BertAttention: 3-16                    (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-17                 (2,362,368)\n",
              "│    │    └─BertOutput: 3-18                       (2,361,600)\n",
              "│    └─BertLayer: 2-12                             --\n",
              "│    │    └─BertAttention: 3-19                    (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-20                 (2,362,368)\n",
              "│    │    └─BertOutput: 3-21                       (2,361,600)\n",
              "│    └─BertLayer: 2-13                             --\n",
              "│    │    └─BertAttention: 3-22                    (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-23                 (2,362,368)\n",
              "│    │    └─BertOutput: 3-24                       (2,361,600)\n",
              "│    └─BertLayer: 2-14                             --\n",
              "│    │    └─BertAttention: 3-25                    (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-26                 (2,362,368)\n",
              "│    │    └─BertOutput: 3-27                       (2,361,600)\n",
              "│    └─BertLayer: 2-15                             --\n",
              "│    │    └─BertAttention: 3-28                    (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-29                 (2,362,368)\n",
              "│    │    └─BertOutput: 3-30                       (2,361,600)\n",
              "├─Dropout: 1-3                                     --\n",
              "├─Flatten: 1-4                                     --\n",
              "├─Linear: 1-5                                      196,864\n",
              "├─Linear: 1-6                                      257\n",
              "├─Linear: 1-7                                      513\n",
              "├─Sigmoid: 1-8                                     --\n",
              "===========================================================================\n",
              "Total params: 94,913,538\n",
              "Trainable params: 197,634\n",
              "Non-trainable params: 94,715,904\n",
              "==========================================================================="
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary( get_custom_bert_model(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d27350ee-fca8-4e35-bfd2-3614e3df7e0e",
      "metadata": {
        "id": "d27350ee-fca8-4e35-bfd2-3614e3df7e0e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}