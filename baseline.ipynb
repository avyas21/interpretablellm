{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f343ad35-e195-4859-a3a7-35e4120d1b69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "f343ad35-e195-4859-a3a7-35e4120d1b69",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "9e6c1b75-186a-488c-8da6-481994247d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install numpy==1.26.0\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install --upgrade ipywidgets\n",
    "!pip install pandas\n",
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2962b9d0-ba93-4ffa-bf14-18aa63fedea6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2962b9d0-ba93-4ffa-bf14-18aa63fedea6",
    "outputId": "4a55f024-ade7-45e5-d11c-17c1d48f07ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  8 23:20:27 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   44C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "n-j8_3zq1UT6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-j8_3zq1UT6",
    "outputId": "ca126bd9-519a-40ff-ec60-597ac9485bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'interpretablellm' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/avyas21/interpretablellm.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "srClFliF1d4O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srClFliF1d4O",
    "outputId": "7d397ce7-f8e3-455a-f8fb-47c5e2f47594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/interpretablellm\n",
      "baseline.ipynb\tbaseline_prompt.txt  data  README.md  setup_dataset.ipynb\n"
     ]
    }
   ],
   "source": [
    "%cd interpretablellm\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b82dd9f-e6d6-46ac-9843-ca25199683dc",
   "metadata": {
    "id": "9b82dd9f-e6d6-46ac-9843-ca25199683dc"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d09ed15-aedc-4fc2-818f-a72d9d98c52f",
   "metadata": {
    "id": "4d09ed15-aedc-4fc2-818f-a72d9d98c52f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b76f9c22-366a-4a15-a179-4c5383ebc244",
   "metadata": {
    "id": "b76f9c22-366a-4a15-a179-4c5383ebc244"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train_data.csv\")\n",
    "test_data = pd.read_csv(\"data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f93876-e2bf-4b48-b96e-49f03c8593b2",
   "metadata": {
    "id": "42f93876-e2bf-4b48-b96e-49f03c8593b2"
   },
   "outputs": [],
   "source": [
    "POSITIVE_WORDS = [\"positive\", \"great\", \"good\", \"happy\", \"amazing\", \"fantastic\", \"yes\"]\n",
    "NEGATIVE_WORDS = [\"negative\", \"bad\", \"sad\", \"terrible\", \"horrible\", \"no\", \"critical\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48213dc3-68d1-4b8b-a454-ec5deed1ee28",
   "metadata": {
    "id": "48213dc3-68d1-4b8b-a454-ec5deed1ee28"
   },
   "outputs": [],
   "source": [
    "def convert_lbl_to_int(label):\n",
    "    if label.lower() in POSITIVE_WORDS:\n",
    "        return 1\n",
    "    if label.lower() in NEGATIVE_WORDS:\n",
    "        return 0\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcc1073e-f664-4053-a2a0-6a866a8ba2b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcc1073e-f664-4053-a2a0-6a866a8ba2b0",
    "outputId": "efa189f4-ca05-4498-d010-ec08c5704317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from torchinfo import summary\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "485XykGLie_x",
   "metadata": {
    "id": "485XykGLie_x"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ZuLuCEEqWxpF",
   "metadata": {
    "id": "ZuLuCEEqWxpF"
   },
   "outputs": [],
   "source": [
    "def get_inputs_labels(df):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for idx, row in train_data.iterrows():\n",
    "        input_text = row['Review']\n",
    "        inputs.append(input_text)\n",
    "        labels.append(1 if row['Sentiment'] == 'positive' else 0)\n",
    "    return inputs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "L53zFoGWaT0q",
   "metadata": {
    "id": "L53zFoGWaT0q"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "inputs, labels = get_inputs_labels(train_data)\n",
    "dataset = TextDataset(inputs, labels, tokenizer, 512)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594c372-0387-4956-b9e6-a362de13ab1b",
   "metadata": {
    "id": "c594c372-0387-4956-b9e6-a362de13ab1b"
   },
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc9d76-4bc4-45cf-8605-cabbb336733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_model():\n",
    "  gpu_available = torch.cuda.is_available()\n",
    "  model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "  if gpu_available:\n",
    "    return model.to(torch.device(\"cuda\"))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823d4e6e-aed8-4d98-86f0-98c7d798def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = get_baseline_model()\n",
    "summary(baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3efd9030-e3ac-4c20-92b5-a82df8b63a4b",
   "metadata": {
    "id": "3efd9030-e3ac-4c20-92b5-a82df8b63a4b"
   },
   "outputs": [],
   "source": [
    "def predict_baseline(df, model, tokenizer, unmasker):\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for idx, row in df.iterrows():\n",
    "        input_text = row['Review']\n",
    "        prediction = predict(input_text, unmasker)\n",
    "        predictions.append(convert_lbl_to_int(prediction))\n",
    "        labels.append(convert_lbl_to_int(row['Sentiment']))\n",
    "    return predictions, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36e84017-3c95-4195-a64e-872de86aa27d",
   "metadata": {
    "id": "36e84017-3c95-4195-a64e-872de86aa27d"
   },
   "outputs": [],
   "source": [
    "def baseline_predict(model, df):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    with torch.no_grad():\n",
    "        for idx, row in df.iterrows():\n",
    "            input_text = row['Review']\n",
    "            encoding = tokenizer(input_text, add_special_tokens=True, max_length = 512, padding='max_length', truncation=True, return_tensors='pt')\n",
    "            if gpu_available:\n",
    "              input_ids = encoding['input_ids'].cuda()\n",
    "              attention_mask = encoding['attention_mask'].cuda()\n",
    "              output = model(encoding['input_ids'].cuda(), encoding['attention_mask'].cuda())\n",
    "            else:\n",
    "              input_ids = encoding['input_ids']\n",
    "              attention_mask = encoding['attention_mask']\n",
    "              output = model(encoding['input_ids'], encoding['attention_mask'])\n",
    "\n",
    "            _, prediction = torch.max(output.logits, dim=1)\n",
    "            predictions.append(prediction.item())\n",
    "            labels.append(convert_lbl_to_int(row['Sentiment']))\n",
    "\n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9DhDookCV4cA",
   "metadata": {
    "id": "9DhDookCV4cA"
   },
   "outputs": [],
   "source": [
    "def baseline_score_model(model, train_df, test_df):\n",
    "    train_f1 = None\n",
    "    test_f1 = None\n",
    "\n",
    "    if train_df is not None:\n",
    "        train_predictions, train_labels = baseline_predict(model, train_df)\n",
    "        train_f1 = f1_score(train_labels, train_predictions, average='micro')\n",
    "\n",
    "    if test_df is not None:\n",
    "        test_predictions, test_labels = baseline_predict(model, test_df)\n",
    "        test_f1 = f1_score(test_labels, test_predictions, average='micro')\n",
    "\n",
    "    return train_f1, test_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f05cf6-0511-4f27-90fc-207b5e4678ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "85f05cf6-0511-4f27-90fc-207b5e4678ef",
    "outputId": "8cbdabe4-2067-43f6-de42-bd3f11e58c2f"
   },
   "outputs": [],
   "source": [
    "def baseline_train_test(model, epochs, dataloader, train_df, test_df, learning_rate = 1e-3, calc_train_f1 = True):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    i = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            i += 1\n",
    "            if i % 10 == 0:\n",
    "                print(loss)\n",
    "            \n",
    "        if calc_train_f1:\n",
    "          train_f1, _ = baseline_score_model(model, train_df, None)\n",
    "          print(\"Epoch: \" + str(epoch) + \" F1: \" + str(train_f1) + \" LOSS: \" + str(loss))\n",
    "    _, test_f1 = baseline_score_model(model, None, test_df)\n",
    "    print(\"TEST F1: \" + str(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f61be6-17ee-42cd-ab37-024e26f63319",
   "metadata": {
    "id": "d0f61be6-17ee-42cd-ab37-024e26f63319"
   },
   "outputs": [],
   "source": [
    "baseline_train_test(baseline_model, 1, dataloader, train_data, test_data, learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b6d9a2-b1cc-438c-bdf2-7cddba7ce1a7",
   "metadata": {
    "id": "89b6d9a2-b1cc-438c-bdf2-7cddba7ce1a7"
   },
   "source": [
    "## Probe Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hs9tJr6xUte3",
   "metadata": {
    "id": "hs9tJr6xUte3"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "import pandas as pd\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, n, randomized=False, linear_1 = None, linear_2 = None, requires_grad = False):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        if randomized:\n",
    "          config = BertConfig()\n",
    "          self.bert = BertModel(config).to(torch.device(\"cuda\"))\n",
    "        else:\n",
    "          self.bert=  BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "            \n",
    "        self.bert.encoder.layer = nn.ModuleList(self.bert.encoder.layer[:n])\n",
    "\n",
    "        if randomized:\n",
    "            # Reinitialize weights for each layer in the encoder\n",
    "            for layer in self.bert.encoder.layer:\n",
    "                for module in layer.modules():\n",
    "                  for mod in module.modules():\n",
    "                      if isinstance(mod, (nn.Linear, nn.Conv2d)):\n",
    "                          # Reinitialize weights for linear and convolution layers\n",
    "                          # print(\"Before Randomization:\", mod.weight)\n",
    "                          nn.init.xavier_uniform_(mod.weight)\n",
    "                          # print(\"After Randomization:\", mod.weight)\n",
    "                          if mod.bias is not None:\n",
    "                              nn.init.zeros_(mod.bias)\n",
    "                      elif isinstance(mod, nn.LayerNorm):\n",
    "                          # Reinitialize LayerNorm layers\n",
    "                          nn.init.ones_(mod.weight)\n",
    "                          nn.init.zeros_(mod.bias)\n",
    "\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "            \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        ### New layers:\n",
    "\n",
    "        if linear_1 is not None:\n",
    "          self.linear_1 = linear_1\n",
    "        else:\n",
    "          self.linear_1 = nn.Linear(768, 256)\n",
    "\n",
    "        if linear_2 is not None:\n",
    "          self.linear_2 = linear_2\n",
    "        else:\n",
    "          self.linear_2 = nn.Linear(256, 1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        output = self.bert(input_ids=ids, attention_mask=mask, output_hidden_states=True)\n",
    "\n",
    "        linear1_output = self.linear_1(output.last_hidden_state[:,0,:])\n",
    "        linear2_output = self.linear_2(self.dropout(linear1_output))\n",
    "        sigmoid_output = self.sigmoid(linear2_output)\n",
    "        return sigmoid_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a62027a-0f6f-4059-a36d-51ef161bfdc8",
   "metadata": {
    "id": "6a62027a-0f6f-4059-a36d-51ef161bfdc8"
   },
   "outputs": [],
   "source": [
    "def get_custom_bert_model(num_bert_layers, randomized_weights = False, linear_1 = None, linear_2 = None, requires_grad = False):\n",
    "  gpu_available = torch.cuda.is_available()\n",
    "  model = CustomBERTModel(num_bert_layers, randomized_weights, linear_1, linear_2, requires_grad)\n",
    "  if gpu_available:\n",
    "    return model.to(torch.device(\"cuda\"))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "qVWM7p9W7FkT",
   "metadata": {
    "id": "qVWM7p9W7FkT"
   },
   "outputs": [],
   "source": [
    "def predict(model, df):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    with torch.no_grad():\n",
    "        for idx, row in df.iterrows():\n",
    "            input_text = row['Review']\n",
    "            encoding = tokenizer(input_text, add_special_tokens=True, max_length = 512, padding='max_length', truncation=True, return_tensors='pt')\n",
    "            if gpu_available:\n",
    "              input_ids = encoding['input_ids'].cuda()\n",
    "              attention_mask = encoding['attention_mask'].cuda()\n",
    "              prediction = model(encoding['input_ids'].cuda(), encoding['attention_mask'].cuda())\n",
    "            else:\n",
    "              input_ids = encoding['input_ids']\n",
    "              attention_mask = encoding['attention_mask']\n",
    "              prediction = model(encoding['input_ids'], encoding['attention_mask'])\n",
    "            predictions.append(1 if prediction > 0.5 else 0)\n",
    "            labels.append(convert_lbl_to_int(row['Sentiment']))\n",
    "\n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "151ed761-27be-4990-942f-841d0b741037",
   "metadata": {
    "id": "151ed761-27be-4990-942f-841d0b741037"
   },
   "outputs": [],
   "source": [
    "def score_model(model, train_df, test_df):\n",
    "    train_f1 = None\n",
    "    test_f1 = None\n",
    "\n",
    "    if train_df is not None:\n",
    "        train_predictions, train_labels = predict(model, train_df)\n",
    "        train_f1 = f1_score(train_labels, train_predictions, average='micro')\n",
    "\n",
    "    if test_df is not None:\n",
    "        test_predictions, test_labels = predict(model, test_df)\n",
    "        test_f1 = f1_score(test_labels, test_predictions, average='micro')\n",
    "\n",
    "    return train_f1, test_f1\n",
    "\n",
    "# print(score_custom_model(model, train_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "q9hGOXhcfrs4",
   "metadata": {
    "id": "q9hGOXhcfrs4"
   },
   "outputs": [],
   "source": [
    "def train_model(model, epochs, dataloader, train_df, learning_rate = 1e-3, calc_train_f1 = True):\n",
    "    criterion = nn.BCELoss() ## If required define your own criterion\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = learning_rate)\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        i = 0\n",
    "        for batch in dataloader:\n",
    "            targets = np.array(batch['label'])\n",
    "            targets = torch.tensor(np.expand_dims(targets,axis=1)).float()\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "\n",
    "            if gpu_available:\n",
    "              targets = targets.cuda()\n",
    "              input_ids = input_ids.cuda()\n",
    "              attention_mask = attention_mask.cuda()\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            if i % 20 == 0:\n",
    "              print(loss)\n",
    "            optimizer.step()\n",
    "            i += 1\n",
    "\n",
    "        if calc_train_f1:\n",
    "          train_f1, _ = score_model(model, train_df, None)\n",
    "          print(\"Epoch: \" + str(epoch) + \" F1: \" + str(train_f1) + \" LOSS: \" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c3e9cee-6067-4933-ab0a-2a8de05ccc0b",
   "metadata": {
    "id": "3c3e9cee-6067-4933-ab0a-2a8de05ccc0b"
   },
   "outputs": [],
   "source": [
    "def baseline_interpretability(dataloader, train_df, test_df, min_n = 1, max_n = 12):\n",
    "    probe_model_12 = get_custom_bert_model(12)\n",
    "    train_model(probe_model_12, 10, dataloader, train_df, 1e-4)\n",
    "    linear_1 = probe_model_12.linear_1\n",
    "    linear_2 = probe_model_12.linear_2\n",
    "\n",
    "    for n in range(min_n, max_n + 1):\n",
    "        print(\"N: \" + str(n))\n",
    "        model = get_custom_bert_model(n, False, linear_1, linear_2)\n",
    "        train_f1, test_f1 = score_model(model, train_df, test_df)\n",
    "        print(\"TRAIN F1: \" + str(train_f1) + \" TEST F1: \" + str(test_f1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "AcswQWUFrPEW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AcswQWUFrPEW",
    "outputId": "b663958a-4480-4bd5-a153-8cfb0391fe16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7211, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6176, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5319, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5455, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 0 F1: 0.843 LOSS: tensor(0.5268, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4765, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4257, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4145, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3101, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.87025 LOSS: tensor(0.3700, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3437, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3309, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3255, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3640, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.87875 LOSS: tensor(0.3233, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3413, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2974, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2716, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.88425 LOSS: tensor(0.3118, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3571, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2969, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2498, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2649, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.890125 LOSS: tensor(0.3439, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3276, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2449, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3463, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2690, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.892 LOSS: tensor(0.3244, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3091, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3418, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.895125 LOSS: tensor(0.2161, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3072, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2298, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2991, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2449, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.897375 LOSS: tensor(0.1759, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2548, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2649, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3082, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2532, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.898625 LOSS: tensor(0.1863, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2276, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2949, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2696, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2557, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.896875 LOSS: tensor(0.2274, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "N: 1\n",
      "TEST F1: 0.524875 TEST F1: 0.504\n",
      "N: 2\n",
      "TEST F1: 0.504375 TEST F1: 0.4995\n",
      "N: 3\n",
      "TEST F1: 0.5 TEST F1: 0.5\n",
      "N: 4\n",
      "TEST F1: 0.5 TEST F1: 0.5\n",
      "N: 5\n",
      "TEST F1: 0.499875 TEST F1: 0.5\n",
      "N: 6\n",
      "TEST F1: 0.524 TEST F1: 0.52\n",
      "N: 7\n",
      "TEST F1: 0.561 TEST F1: 0.557\n",
      "N: 8\n",
      "TEST F1: 0.5605 TEST F1: 0.554\n",
      "N: 9\n",
      "TEST F1: 0.587625 TEST F1: 0.581\n",
      "N: 10\n",
      "TEST F1: 0.721625 TEST F1: 0.7235\n",
      "N: 11\n",
      "TEST F1: 0.872375 TEST F1: 0.8725\n",
      "N: 12\n",
      "TEST F1: 0.896875 TEST F1: 0.8945\n"
     ]
    }
   ],
   "source": [
    "baseline_interpretability(dataloader, train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "q8q83o7zBZly",
   "metadata": {
    "id": "q8q83o7zBZly"
   },
   "outputs": [],
   "source": [
    "def score_all_randomized_models(dataloader, train_df, test_df, epochs, max_n, learning_rate = 1e-3):\n",
    "    model_scores = []\n",
    "    for n in range(1,max_n + 1):\n",
    "        print(\"N: \" + str(n))\n",
    "        model = get_custom_bert_model(n, True)\n",
    "        train_model(model, epochs, dataloader, train_df, learning_rate)\n",
    "        _, test_f1 = score_model(model, None, test_df)\n",
    "        print(\"TEST F1: \" + str(test_f1))\n",
    "        model_scores.append([n, test_f1])\n",
    "\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1949ee-a200-460d-a868-68e3a313b19e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a1949ee-a200-460d-a868-68e3a313b19e",
    "outputId": "e3fe799c-9294-4100-841a-e878ac141319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 1\n",
      "Epoch: 0 F1: 0.618875 LOSS: tensor(0.6379, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-134-70b63bbe3862>\", line 1, in <cell line: 0>\n",
      "    model_scores = score_all_randomized_models(dataloader, train_data, test_data, 10, 12)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-130-bc5c5454ae21>\", line 6, in score_all_randomized_models\n",
      "    train_model(model, epochs, dataloader, train_df, learning_rate)\n",
      "  File \"<ipython-input-133-fd5dc9de79d6>\", line 29, in train_model\n",
      "    train_f1, _ = score_model(model, train_df, None)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-126-c3b53445eb9a>\", line 6, in score_model\n",
      "    train_predictions, train_labels = predict(model, train_df)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-125-392c8d43dee1>\", line 9, in predict\n",
      "    encoding = tokenizer(input_text, add_special_tokens=True, max_length = 512, padding='max_length', truncation=True, return_tensors='pt')\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2868, in __call__\n",
      "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2978, in _call_one\n",
      "    return self.encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3054, in encode_plus\n",
      "    return self._encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 801, in _encode_plus\n",
      "    first_ids = get_input_ids(text)\n",
      "                ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 768, in get_input_ids\n",
      "    tokens = self.tokenize(text, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 662, in tokenize\n",
      "    tokens = self.tokens_trie.split(text)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line None, in split\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
      "    traceback_info = getframeinfo(tb, context)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
      "    start = lineno - 1 - context//2\n",
      "            ~~~~~~~^~~\n",
      "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-134-70b63bbe3862>\", line 1, in <cell line: 0>\n",
      "    model_scores = score_all_randomized_models(dataloader, train_data, test_data, 10, 12)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-130-bc5c5454ae21>\", line 6, in score_all_randomized_models\n",
      "    train_model(model, epochs, dataloader, train_df, learning_rate)\n",
      "  File \"<ipython-input-133-fd5dc9de79d6>\", line 29, in train_model\n",
      "    train_f1, _ = score_model(model, train_df, None)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-126-c3b53445eb9a>\", line 6, in score_model\n",
      "    train_predictions, train_labels = predict(model, train_df)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-125-392c8d43dee1>\", line 9, in predict\n",
      "    encoding = tokenizer(input_text, add_special_tokens=True, max_length = 512, padding='max_length', truncation=True, return_tensors='pt')\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2868, in __call__\n",
      "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2978, in _call_one\n",
      "    return self.encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3054, in encode_plus\n",
      "    return self._encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 801, in _encode_plus\n",
      "    first_ids = get_input_ids(text)\n",
      "                ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 768, in get_input_ids\n",
      "    tokens = self.tokenize(text, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 662, in tokenize\n",
      "    tokens = self.tokens_trie.split(text)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line None, in split\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "           ^^^^^^^^^^^^\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
      "    traceback_info = getframeinfo(tb, context)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
      "    start = lineno - 1 - context//2\n",
      "            ~~~~~~~^~~\n",
      "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-134-70b63bbe3862>\", line 1, in <cell line: 0>\n",
      "    model_scores = score_all_randomized_models(dataloader, train_data, test_data, 10, 12)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-130-bc5c5454ae21>\", line 6, in score_all_randomized_models\n",
      "    train_model(model, epochs, dataloader, train_df, learning_rate)\n",
      "  File \"<ipython-input-133-fd5dc9de79d6>\", line 29, in train_model\n",
      "    train_f1, _ = score_model(model, train_df, None)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-126-c3b53445eb9a>\", line 6, in score_model\n",
      "    train_predictions, train_labels = predict(model, train_df)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<ipython-input-125-392c8d43dee1>\", line 9, in predict\n",
      "    encoding = tokenizer(input_text, add_special_tokens=True, max_length = 512, padding='max_length', truncation=True, return_tensors='pt')\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2868, in __call__\n",
      "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2978, in _call_one\n",
      "    return self.encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3054, in encode_plus\n",
      "    return self._encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 801, in _encode_plus\n",
      "    first_ids = get_input_ids(text)\n",
      "                ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 768, in get_input_ids\n",
      "    tokens = self.tokenize(text, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 662, in tokenize\n",
      "    tokens = self.tokens_trie.split(text)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line None, in split\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "           ^^^^^^^^^^^^\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
      "    return runner(coro)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "           ^^^^^^^^^^^^\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
      "    traceback_info = getframeinfo(tb, context)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
      "    start = lineno - 1 - context//2\n",
      "            ~~~~~~~^~~\n",
      "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n"
     ]
    }
   ],
   "source": [
    "model_scores = score_all_randomized_models(dataloader, train_data, test_data, 10, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bb3b666-1ec1-41f8-b58f-ae6d265b533a",
   "metadata": {
    "id": "5bb3b666-1ec1-41f8-b58f-ae6d265b533a"
   },
   "outputs": [],
   "source": [
    "def score_all_probe_models(dataloader, train_df, test_df, epochs, max_n, learning_rate = 1e-3):\n",
    "    model_scores = []\n",
    "    for n in range(1,max_n + 1):\n",
    "        print(\"N: \" + str(n))\n",
    "        model = get_custom_bert_model(n)\n",
    "        train_model(model, epochs, dataloader, train_df, learning_rate)\n",
    "        _, test_f1 = score_model(model, None, test_df)\n",
    "        print(\"TEST F1: \" + str(test_f1))\n",
    "        model_scores.append([n, test_f1])\n",
    "\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8lTdl-n_zyXY",
   "metadata": {
    "id": "8lTdl-n_zyXY"
   },
   "source": [
    "## Scalar Mixing Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "Ltfx0_XMzxeh",
   "metadata": {
    "id": "Ltfx0_XMzxeh"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "import pandas as pd\n",
    "\n",
    "class ScalarMixingWeightModel(nn.Module):\n",
    "    def __init__(self, n, i):\n",
    "        super(ScalarMixingWeightModel, self).__init__()\n",
    "\n",
    "        self.bert= BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.bert.encoder.layer = nn.ModuleList(self.bert.encoder.layer[:n])\n",
    "        self.n = n\n",
    "        self.layer_weights = nn.Parameter(torch.ones(self.n))\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.i = i\n",
    "\n",
    "        self.gamma = nn.Parameter(torch.ones(1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        ### New layers:\n",
    "        if self.i == 1:\n",
    "          self.linear1 = nn.Linear(768, 1)\n",
    "        elif self.i == 2:\n",
    "          self.linear1 = nn.Linear(768, 384)\n",
    "          self.linear2 = nn.Linear(384, 1)\n",
    "        elif self.i == 3:\n",
    "          self.linear1 = nn.Linear(768, 384)\n",
    "          self.linear2 = nn.Linear(384, 192)\n",
    "          self.linear3 = nn.Linear(192, 1)\n",
    "        elif self.i == 4:\n",
    "          self.linear1 = nn.Linear(768, 384)\n",
    "          self.linear2 = nn.Linear(384, 192)\n",
    "          self.linear3 = nn.Linear(192, 96)\n",
    "          self.linear4 = nn.Linear(96, 1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        outputs = self.bert(input_ids=ids, attention_mask=mask, output_hidden_states=True)\n",
    "\n",
    "        hidden_states = outputs.hidden_states[1:1 + self.n]\n",
    "\n",
    "        normalized_weights = self.softmax(self.layer_weights)\n",
    "        scalar_mixing_weight = self.gamma * sum(normalized_weights[i] * hidden_states[i] for i in range(self.n))\n",
    "\n",
    "        if self.i == 1:\n",
    "          linear1_output = self.dropout(self.linear1(scalar_mixing_weight[:, 0, :]))\n",
    "          sigmoid_output = self.sigmoid(linear1_output)\n",
    "        elif self.i == 2:\n",
    "          linear1_output = self.linear1(scalar_mixing_weight[:, 0, :])\n",
    "          linear2_output = self.linear2(self.dropout(linear1_output))\n",
    "          sigmoid_output = self.sigmoid(linear2_output)\n",
    "        elif self.i == 3:\n",
    "          linear1_output = self.linear1(scalar_mixing_weight[:, 0, :])\n",
    "          linear2_output = self.linear2(self.dropout(linear1_output))\n",
    "          linear3_output = self.linear3(self.dropout(linear2_output))\n",
    "          sigmoid_output = self.sigmoid(linear3_output)\n",
    "        elif self.i == 4:\n",
    "          linear1_output = self.linear1(scalar_mixing_weight[:, 0, :])\n",
    "          linear2_output = self.linear2(self.dropout(linear1_output))\n",
    "          linear3_output = self.linear3(self.dropout(linear2_output))\n",
    "          linear4_output = self.linear4(self.dropout(linear3_output))\n",
    "          sigmoid_output = self.sigmoid(linear4_output)\n",
    "\n",
    "        return sigmoid_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "lGp5exkZ17M_",
   "metadata": {
    "id": "lGp5exkZ17M_"
   },
   "outputs": [],
   "source": [
    "def get_scalar_mixing_model(num_bert_layers, i):\n",
    "  gpu_available = torch.cuda.is_available()\n",
    "  model = ScalarMixingWeightModel(num_bert_layers, i)\n",
    "\n",
    "  if gpu_available:\n",
    "    return model.to(torch.device(\"cuda\"))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "uhSJ9GBk1__M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "collapsed": true,
    "id": "uhSJ9GBk1__M",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3d119c8a-606a-49af-da0b-06a974d1058b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(19.0966, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(37.8466, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(12.8466, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(22.2649, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(34.7649, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(15.9716, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(12.9332, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(19.1399, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(28.4716, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(19.0749, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(19.1182, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(19.0749, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 0 F1: 0.5 LOSS: tensor(37.7166, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(59.3750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(56.2500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1ee9f25a95ea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtest_scalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scalar_mixing_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_scalar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_scalar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_scalar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-f45f65e4e4ba>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, epochs, dataloader, train_df, learning_rate, calc_train_f1)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[1;32m    522\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     def backward(\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disable_current_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0mguard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DisableFuncTorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    623\u001b[0m                         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    355\u001b[0m         )\n\u001b[1;32m    356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             nonzero_finite_vals = torch.masked_select(\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weights = {}\n",
    "for i in range(11,13):\n",
    "  test_scalar = get_scalar_mixing_model(i,1)\n",
    "  train_model(test_scalar, 10, dataloader, train_data, learning_rate = 0.1)\n",
    "  print(i, \":\", test_scalar.layer_weights)\n",
    "  weights[i] = test_scalar.layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GsEo-F0ghfj8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GsEo-F0ghfj8",
    "outputId": "d2ba4cea-9109-49e9-b76e-e43b8ad87fd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 F1: 0.5 LOSS: tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.579 LOSS: tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.747375 LOSS: tensor(0.6665, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.76175 LOSS: tensor(0.4873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.754875 LOSS: tensor(0.4700, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.771375 LOSS: tensor(0.3286, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.817375 LOSS: tensor(0.4258, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.808375 LOSS: tensor(0.3882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.7935 LOSS: tensor(0.6432, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.827375 LOSS: tensor(0.3705, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.1 Number of layers 1\n",
      "Epoch: 0 F1: 0.5 LOSS: tensor(51.5625, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.5 LOSS: tensor(62.5000, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.5 LOSS: tensor(56.2500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.1 Number of layers 2\n",
      "Epoch: 0 F1: 0.5 LOSS: tensor(32.8125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.5 LOSS: tensor(56.2500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.5 LOSS: tensor(42.1875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.5 LOSS: tensor(57.8125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.5 LOSS: tensor(42.1875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.1 Number of layers 3\n",
      "Epoch: 0 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.5 LOSS: tensor(51.5625, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.5 LOSS: tensor(39.0625, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.1 Number of layers 4\n",
      "Epoch: 0 F1: 0.688625 LOSS: tensor(0.6729, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.72625 LOSS: tensor(0.5735, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.7225 LOSS: tensor(0.4890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.778 LOSS: tensor(0.4555, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.797125 LOSS: tensor(0.4818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.766375 LOSS: tensor(0.5095, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.81625 LOSS: tensor(0.3692, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.81525 LOSS: tensor(0.4498, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.823 LOSS: tensor(0.3185, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.8255 LOSS: tensor(0.4187, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.01 Number of layers 1\n",
      "Epoch: 0 F1: 0.623625 LOSS: tensor(0.5963, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.755375 LOSS: tensor(0.5610, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.773625 LOSS: tensor(0.4210, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.8115 LOSS: tensor(0.4335, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.80525 LOSS: tensor(0.3416, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.8125 LOSS: tensor(0.4147, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.8195 LOSS: tensor(0.4914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.80625 LOSS: tensor(0.4377, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.719 LOSS: tensor(0.3938, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.80725 LOSS: tensor(0.3015, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.01 Number of layers 2\n",
      "Epoch: 0 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.5 LOSS: tensor(59.3750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.5 LOSS: tensor(43.7500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.5 LOSS: tensor(57.8125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.5 LOSS: tensor(65.6250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.01 Number of layers 3\n",
      "Epoch: 0 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.5 LOSS: tensor(43.7500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.01 Number of layers 4\n",
      "Epoch: 0 F1: 0.622875 LOSS: tensor(0.7243, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.637875 LOSS: tensor(0.6641, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.644875 LOSS: tensor(0.6571, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.66575 LOSS: tensor(0.6701, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.6845 LOSS: tensor(0.6082, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.693125 LOSS: tensor(0.5579, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.714375 LOSS: tensor(0.5850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.734625 LOSS: tensor(0.5675, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.728 LOSS: tensor(0.5235, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.75325 LOSS: tensor(0.5115, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.001 Number of layers 1\n",
      "Epoch: 0 F1: 0.67325 LOSS: tensor(0.6584, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.710625 LOSS: tensor(0.5366, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.751375 LOSS: tensor(0.5209, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.786125 LOSS: tensor(0.4284, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.800375 LOSS: tensor(0.5209, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.7775 LOSS: tensor(0.3774, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.783625 LOSS: tensor(0.4044, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.814875 LOSS: tensor(0.4114, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.784625 LOSS: tensor(0.3569, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.82025 LOSS: tensor(0.4046, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.001 Number of layers 2\n",
      "Epoch: 0 F1: 0.643875 LOSS: tensor(0.6335, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.6025 LOSS: tensor(0.6195, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.75075 LOSS: tensor(0.4377, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.792625 LOSS: tensor(0.3910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.7925 LOSS: tensor(0.3448, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.81275 LOSS: tensor(0.4162, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.81725 LOSS: tensor(0.4785, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.81775 LOSS: tensor(0.5427, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.816375 LOSS: tensor(0.4804, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.74775 LOSS: tensor(0.4635, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.001 Number of layers 3\n",
      "Epoch: 0 F1: 0.599375 LOSS: tensor(0.6650, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.7395 LOSS: tensor(0.5235, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.78475 LOSS: tensor(0.4132, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.763875 LOSS: tensor(0.4276, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.80175 LOSS: tensor(0.4442, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.71925 LOSS: tensor(0.4258, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.8145 LOSS: tensor(0.5349, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.82225 LOSS: tensor(0.5277, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.812875 LOSS: tensor(0.4315, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.813375 LOSS: tensor(0.3786, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.001 Number of layers 4\n",
      "Epoch: 0 F1: 0.499625 LOSS: tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.583 LOSS: tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.57775 LOSS: tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.5655 LOSS: tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.61075 LOSS: tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.609375 LOSS: tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.61575 LOSS: tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.619625 LOSS: tensor(0.6795, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.623875 LOSS: tensor(0.6763, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.626625 LOSS: tensor(0.6737, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.0001 Number of layers 1\n",
      "Epoch: 0 F1: 0.62725 LOSS: tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.63025 LOSS: tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.656 LOSS: tensor(0.6105, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.665125 LOSS: tensor(0.6588, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.691 LOSS: tensor(0.5975, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.70775 LOSS: tensor(0.5938, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.708 LOSS: tensor(0.6180, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.735 LOSS: tensor(0.5417, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.740875 LOSS: tensor(0.5361, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.755125 LOSS: tensor(0.4723, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.0001 Number of layers 2\n",
      "Epoch: 0 F1: 0.62875 LOSS: tensor(0.6600, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.626875 LOSS: tensor(0.6630, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.647125 LOSS: tensor(0.6467, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.678625 LOSS: tensor(0.5910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.71625 LOSS: tensor(0.5632, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.71625 LOSS: tensor(0.4906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.766125 LOSS: tensor(0.4897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.747 LOSS: tensor(0.3912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.754 LOSS: tensor(0.5500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.774375 LOSS: tensor(0.5170, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.0001 Number of layers 3\n",
      "Epoch: 0 F1: 0.519125 LOSS: tensor(0.6764, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 F1: 0.60725 LOSS: tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 F1: 0.645125 LOSS: tensor(0.6653, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 F1: 0.6925 LOSS: tensor(0.5769, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 F1: 0.747625 LOSS: tensor(0.4810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 5 F1: 0.74725 LOSS: tensor(0.4977, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 6 F1: 0.77625 LOSS: tensor(0.4830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 7 F1: 0.789 LOSS: tensor(0.4862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 8 F1: 0.79275 LOSS: tensor(0.5131, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 9 F1: 0.799625 LOSS: tensor(0.4610, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Learning rate: 0.0001 Number of layers 4\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.1, 0.01, 0.001, 0.0001]\n",
    "for lr in lrs:\n",
    "  for i in range(1,5):\n",
    "    test_scalar = get_scalar_mixing_model(2, i)\n",
    "    train_model(test_scalar, 10, dataloader, train_data, learning_rate = lr)\n",
    "    print(\"Learning rate:\", lr, \"Number of layers\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8f63b-329d-4066-b72b-2354e3efc9e2",
   "metadata": {
    "id": "40f8f63b-329d-4066-b72b-2354e3efc9e2"
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1b985c-3ce7-41f2-90cb-a4a8059794d6",
   "metadata": {
    "id": "2c1b985c-3ce7-41f2-90cb-a4a8059794d6",
    "outputId": "94e5ebe3-9b8b-4fbe-fb8b-718d9d38212d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "BertModel                                               --\n",
       "├─BertEmbeddings: 1-1                                   --\n",
       "│    └─Embedding: 2-1                                   (23,440,896)\n",
       "│    └─Embedding: 2-2                                   (393,216)\n",
       "│    └─Embedding: 2-3                                   (1,536)\n",
       "│    └─LayerNorm: 2-4                                   (1,536)\n",
       "│    └─Dropout: 2-5                                     --\n",
       "├─BertEncoder: 1-2                                      --\n",
       "│    └─ModuleList: 2-6                                  --\n",
       "│    │    └─BertLayer: 3-1                              (7,087,872)\n",
       "│    │    └─BertLayer: 3-2                              (7,087,872)\n",
       "│    │    └─BertLayer: 3-3                              (7,087,872)\n",
       "│    │    └─BertLayer: 3-4                              (7,087,872)\n",
       "│    │    └─BertLayer: 3-5                              (7,087,872)\n",
       "│    │    └─BertLayer: 3-6                              (7,087,872)\n",
       "│    │    └─BertLayer: 3-7                              (7,087,872)\n",
       "│    │    └─BertLayer: 3-8                              (7,087,872)\n",
       "│    │    └─BertLayer: 3-9                              (7,087,872)\n",
       "│    │    └─BertLayer: 3-10                             (7,087,872)\n",
       "│    │    └─BertLayer: 3-11                             7,087,872\n",
       "│    │    └─BertLayer: 3-12                             7,087,872\n",
       "├─BertPooler: 1-3                                       --\n",
       "│    └─Linear: 2-7                                      590,592\n",
       "│    └─Tanh: 2-8                                        --\n",
       "================================================================================\n",
       "Total params: 109,482,240\n",
       "Trainable params: 14,766,336\n",
       "Non-trainable params: 94,715,904\n",
       "================================================================================"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c58c62b-6c11-4810-bd52-b3d58aa7f853",
   "metadata": {
    "id": "0c58c62b-6c11-4810-bd52-b3d58aa7f853",
    "outputId": "30c9add2-5227-4935-942a-1a5d847cac67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "CustomBERTModel                                    --\n",
       "├─BertEmbeddings: 1-1                              --\n",
       "│    └─Embedding: 2-1                              (23,440,896)\n",
       "│    └─Embedding: 2-2                              (393,216)\n",
       "│    └─Embedding: 2-3                              (1,536)\n",
       "│    └─LayerNorm: 2-4                              (1,536)\n",
       "│    └─Dropout: 2-5                                --\n",
       "├─ModuleList: 1-2                                  --\n",
       "│    └─BertLayer: 2-6                              --\n",
       "│    │    └─BertAttention: 3-1                     (2,363,904)\n",
       "│    │    └─BertIntermediate: 3-2                  (2,362,368)\n",
       "│    │    └─BertOutput: 3-3                        (2,361,600)\n",
       "│    └─BertLayer: 2-7                              --\n",
       "│    │    └─BertAttention: 3-4                     (2,363,904)\n",
       "│    │    └─BertIntermediate: 3-5                  (2,362,368)\n",
       "│    │    └─BertOutput: 3-6                        (2,361,600)\n",
       "│    └─BertLayer: 2-8                              --\n",
       "│    │    └─BertAttention: 3-7                     (2,363,904)\n",
       "│    │    └─BertIntermediate: 3-8                  (2,362,368)\n",
       "│    │    └─BertOutput: 3-9                        (2,361,600)\n",
       "│    └─BertLayer: 2-9                              --\n",
       "│    │    └─BertAttention: 3-10                    (2,363,904)\n",
       "│    │    └─BertIntermediate: 3-11                 (2,362,368)\n",
       "│    │    └─BertOutput: 3-12                       (2,361,600)\n",
       "│    └─BertLayer: 2-10                             --\n",
       "│    │    └─BertAttention: 3-13                    (2,363,904)\n",
       "│    │    └─BertIntermediate: 3-14                 (2,362,368)\n",
       "│    │    └─BertOutput: 3-15                       (2,361,600)\n",
       "│    └─BertLayer: 2-11                             --\n",
       "│    │    └─BertAttention: 3-16                    (2,363,904)\n",
       "│    │    └─BertIntermediate: 3-17                 (2,362,368)\n",
       "│    │    └─BertOutput: 3-18                       (2,361,600)\n",
       "│    └─BertLayer: 2-12                             --\n",
       "│    │    └─BertAttention: 3-19                    (2,363,904)\n",
       "│    │    └─BertIntermediate: 3-20                 (2,362,368)\n",
       "│    │    └─BertOutput: 3-21                       (2,361,600)\n",
       "│    └─BertLayer: 2-13                             --\n",
       "│    │    └─BertAttention: 3-22                    (2,363,904)\n",
       "│    │    └─BertIntermediate: 3-23                 (2,362,368)\n",
       "│    │    └─BertOutput: 3-24                       (2,361,600)\n",
       "│    └─BertLayer: 2-14                             --\n",
       "│    │    └─BertAttention: 3-25                    (2,363,904)\n",
       "│    │    └─BertIntermediate: 3-26                 (2,362,368)\n",
       "│    │    └─BertOutput: 3-27                       (2,361,600)\n",
       "│    └─BertLayer: 2-15                             --\n",
       "│    │    └─BertAttention: 3-28                    (2,363,904)\n",
       "│    │    └─BertIntermediate: 3-29                 (2,362,368)\n",
       "│    │    └─BertOutput: 3-30                       (2,361,600)\n",
       "├─Dropout: 1-3                                     --\n",
       "├─Flatten: 1-4                                     --\n",
       "├─Linear: 1-5                                      196,864\n",
       "├─Linear: 1-6                                      257\n",
       "├─Linear: 1-7                                      513\n",
       "├─Sigmoid: 1-8                                     --\n",
       "===========================================================================\n",
       "Total params: 94,913,538\n",
       "Trainable params: 197,634\n",
       "Non-trainable params: 94,715,904\n",
       "==========================================================================="
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary( get_custom_bert_model(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27350ee-fca8-4e35-bfd2-3614e3df7e0e",
   "metadata": {
    "id": "d27350ee-fca8-4e35-bfd2-3614e3df7e0e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
