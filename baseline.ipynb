{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f343ad35-e195-4859-a3a7-35e4120d1b69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "f343ad35-e195-4859-a3a7-35e4120d1b69",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "861a413e-d24e-476a-8035-ebf2dff0ff0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Collecting numpy==1.26.0\n",
      "  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.19 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.0\n",
      "Requirement already satisfied: tensorflow[and-cuda] in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.26.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.37.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.5.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.3.0.75 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (9.3.0.75)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.3.61 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (11.2.3.61)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.6.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (10.3.6.82)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.3.83 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (11.6.3.83)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow[and-cuda]) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow[and-cuda]) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow[and-cuda]) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow[and-cuda]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow[and-cuda]) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow[and-cuda]) (0.1.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting comm>=0.1.3 (from ipywidgets)\n",
      "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (75.1.0)\n",
      "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets)\n",
      "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jedi, comm, ipywidgets\n",
      "  Attempting uninstall: widgetsnbextension\n",
      "    Found existing installation: widgetsnbextension 3.6.10\n",
      "    Uninstalling widgetsnbextension-3.6.10:\n",
      "      Successfully uninstalled widgetsnbextension-3.6.10\n",
      "  Attempting uninstall: ipywidgets\n",
      "    Found existing installation: ipywidgets 7.7.1\n",
      "    Uninstalling ipywidgets-7.7.1:\n",
      "      Successfully uninstalled ipywidgets-7.7.1\n",
      "Successfully installed comm-0.2.2 ipywidgets-8.1.5 jedi-0.19.2 widgetsnbextension-4.0.13\n",
      "Requirement already satisfied: tf-keras in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.26.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install numpy==1.26.0\n",
    "!pip install tensorflow[and-cuda]\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install --upgrade ipywidgets\n",
    "!pip install tf-keras\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2962b9d0-ba93-4ffa-bf14-18aa63fedea6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2962b9d0-ba93-4ffa-bf14-18aa63fedea6",
    "outputId": "bd7a40fb-66da-4ff6-a777-828a13980d3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b82dd9f-e6d6-46ac-9843-ca25199683dc",
   "metadata": {
    "id": "9b82dd9f-e6d6-46ac-9843-ca25199683dc"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d09ed15-aedc-4fc2-818f-a72d9d98c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76f9c22-366a-4a15-a179-4c5383ebc244",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train_data.csv\")\n",
    "test_data = pd.read_csv(\"data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48213dc3-68d1-4b8b-a454-ec5deed1ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lbl_to_int(label):\n",
    "    if label.lower() == \"positive\":\n",
    "        return 1\n",
    "    if label.lower() == \"negative\":\n",
    "        return 0\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594c372-0387-4956-b9e6-a362de13ab1b",
   "metadata": {
    "id": "c594c372-0387-4956-b9e6-a362de13ab1b"
   },
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc1073e-f664-4053-a2a0-6a866a8ba2b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcc1073e-f664-4053-a2a0-6a866a8ba2b0",
    "outputId": "d5ea6b1f-165f-4e15-e085-34083f8deae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2025-02-24 09:52:30.220609: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740390750.243675   47148 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740390750.250726   47148 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-24 09:52:30.276708: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d9d4b2-68ac-433e-933f-407c97a5807b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a review, classify it as positive or negative sentiment.\n",
      "Review: Test Prompt\n",
      "This review has a [MASK] sentiment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_prompt(review):\n",
    "  with open(\"baseline_prompt.txt\", \"r\") as file:\n",
    "    prompt = file.read()\n",
    "  prompt = prompt.replace(\"<REVIEW>\", review)\n",
    "  return prompt\n",
    "\n",
    "print(get_prompt(\"Test Prompt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f71ba217-62df-4dc0-8b14-638e35080ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "# print(inputs)\n",
    "# with torch.no_grad():\n",
    "#     logits = baseline_model(**inputs).logits\n",
    "#     print(logits.shape)\n",
    "\n",
    "# predicted_class_id = logits.argmax().item()\n",
    "# print(baseline_model.config.id2label[predicted_class_id])\n",
    "\n",
    "# summary(baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943dccdc-d64d-438c-8285-42ae4cac65aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model and tokenizer\n",
    "baseline_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "baseline_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "baseline_unmasker = pipeline('fill-mask', model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36e84017-3c95-4195-a64e-872de86aa27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(review, unmasker):\n",
    "  prompt = get_prompt(review)\n",
    "  predictions = unmasker(prompt)\n",
    "  for prediction in predictions:\n",
    "    if(prediction['token_str'] == 'negative' or prediction['token_str'] == 'positive'):\n",
    "      return prediction['token_str']\n",
    "\n",
    "  return \"<NOT FOUND>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3efd9030-e3ac-4c20-92b5-a82df8b63a4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3efd9030-e3ac-4c20-92b5-a82df8b63a4b",
    "outputId": "635f2c76-af5d-4a56-ee63-a2feefaf84c0"
   },
   "outputs": [],
   "source": [
    "def predict_baseline(df, model, tokenizer, unmasker):\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for idx, row in df.iterrows():\n",
    "        input_text = row['Review']\n",
    "        prompt = get_prompt(input_text)\n",
    "        prediction = predict(input_text, unmasker)\n",
    "        predictions.append(convert_lbl_to_int(prediction))\n",
    "        labels.append(convert_lbl_to_int(row['Sentiment']))\n",
    "\n",
    "    return predictions, labels\n",
    "\n",
    "predictions, labels = predict_baseline(train_data, baseline_model, baseline_tokenizer, baseline_unmasker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9DhDookCV4cA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9DhDookCV4cA",
    "outputId": "a49f3bef-4fa1-4d67-ee12-7aa41b39eb40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85f05cf6-0511-4f27-90fc-207b5e4678ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: -1, Count: 149\n",
      "Value: 0, Count: 581\n",
      "Value: 1, Count: 7270\n"
     ]
    }
   ],
   "source": [
    "values, counts = np.unique(np.array(predictions), return_counts=True)\n",
    "\n",
    "for v, c in zip(values, counts):\n",
    "    print(f\"Value: {v}, Count: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0f61be6-17ee-42cd-ab37-024e26f63319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.556375\n"
     ]
    }
   ],
   "source": [
    "print( f1_score(labels, predictions, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b6d9a2-b1cc-438c-bdf2-7cddba7ce1a7",
   "metadata": {},
   "source": [
    "## Probe Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hs9tJr6xUte3",
   "metadata": {
    "id": "hs9tJr6xUte3"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "import pandas as pd\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, bert_embedding_layer, bert_encoder_layers):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert_embedding_layer = bert_embedding_layer\n",
    "        self.bert_encoder_layers = bert_encoder_layers\n",
    "        \n",
    "        # Freeze the embedding layer\n",
    "        for param in self.bert_embedding_layer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.bert_encoder_layers.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        ### New layers:\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(768, 256)\n",
    "        self.linear2 = nn.Linear(256, 1)\n",
    "        self.linear3 = nn.Linear(512, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        embedding_output = self.bert_embedding_layer(ids)\n",
    "        encoder_outputs = embedding_output\n",
    "        for i, layer_module in enumerate(self.bert_encoder_layers):\n",
    "          encoder_outputs = layer_module(encoder_outputs)[0]\n",
    "        \n",
    "        linear1_output = self.linear1(encoder_outputs)\n",
    "        linear2_output = self.linear2(linear1_output)\n",
    "        flattened_output = self.flatten(linear2_output)\n",
    "        linear3_output = self.linear3(flattened_output)\n",
    "        sigmoid_output = self.sigmoid(linear3_output)\n",
    "        return sigmoid_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a62027a-0f6f-4059-a36d-51ef161bfdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_bert_model(num_bert_layers):\n",
    "    return CustomBERTModel(baseline_model.embeddings, baseline_model.encoder.layer[:num_bert_layers]).to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c3e9cee-6067-4933-ab0a-2a8de05ccc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "CustomBERTModel                                    --\n",
       "â”œâ”€BertEmbeddings: 1-1                              --\n",
       "â”‚    â””â”€Embedding: 2-1                              (23,440,896)\n",
       "â”‚    â””â”€Embedding: 2-2                              (393,216)\n",
       "â”‚    â””â”€Embedding: 2-3                              (1,536)\n",
       "â”‚    â””â”€LayerNorm: 2-4                              (1,536)\n",
       "â”‚    â””â”€Dropout: 2-5                                --\n",
       "â”œâ”€ModuleList: 1-2                                  --\n",
       "â”‚    â””â”€BertLayer: 2-6                              --\n",
       "â”‚    â”‚    â””â”€BertAttention: 3-1                     (2,363,904)\n",
       "â”‚    â”‚    â””â”€BertIntermediate: 3-2                  (2,362,368)\n",
       "â”‚    â”‚    â””â”€BertOutput: 3-3                        (2,361,600)\n",
       "â”‚    â””â”€BertLayer: 2-7                              --\n",
       "â”‚    â”‚    â””â”€BertAttention: 3-4                     (2,363,904)\n",
       "â”‚    â”‚    â””â”€BertIntermediate: 3-5                  (2,362,368)\n",
       "â”‚    â”‚    â””â”€BertOutput: 3-6                        (2,361,600)\n",
       "â”‚    â””â”€BertLayer: 2-8                              --\n",
       "â”‚    â”‚    â””â”€BertAttention: 3-7                     (2,363,904)\n",
       "â”‚    â”‚    â””â”€BertIntermediate: 3-8                  (2,362,368)\n",
       "â”‚    â”‚    â””â”€BertOutput: 3-9                        (2,361,600)\n",
       "â”‚    â””â”€BertLayer: 2-9                              --\n",
       "â”‚    â”‚    â””â”€BertAttention: 3-10                    (2,363,904)\n",
       "â”‚    â”‚    â””â”€BertIntermediate: 3-11                 (2,362,368)\n",
       "â”‚    â”‚    â””â”€BertOutput: 3-12                       (2,361,600)\n",
       "â”œâ”€Flatten: 1-3                                     --\n",
       "â”œâ”€Linear: 1-4                                      196,864\n",
       "â”œâ”€Linear: 1-5                                      257\n",
       "â”œâ”€Linear: 1-6                                      513\n",
       "â”œâ”€Sigmoid: 1-7                                     --\n",
       "===========================================================================\n",
       "Total params: 52,386,306\n",
       "Trainable params: 197,634\n",
       "Non-trainable params: 52,188,672\n",
       "==========================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(get_custom_bert_model(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "727fa289-e71a-4d8b-8776-aa6a461b07fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_seq_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "# print(inputs)\n",
    "# with torch.no_grad():\n",
    "#     logits = bert_seq_model(**inputs).logits\n",
    "#     print(logits.shape)\n",
    "\n",
    "# predicted_class_id = logits.argmax().item()\n",
    "# print(bert_seq_model.config.id2label[predicted_class_id])\n",
    "\n",
    "# summary(bert_seq_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ZuLuCEEqWxpF",
   "metadata": {
    "id": "ZuLuCEEqWxpF"
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "labels = []\n",
    "for idx, row in train_data.iterrows():\n",
    "    input_text = row['Review']\n",
    "    inputs.append(input_text)\n",
    "    labels.append(1 if row['Sentiment'] == 'positive' else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "485XykGLie_x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "485XykGLie_x",
    "outputId": "37bd8dae-b074-4a56-cce4-a473be501f9a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "L53zFoGWaT0q",
   "metadata": {
    "id": "L53zFoGWaT0q"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dataset = TextDataset(inputs, labels, tokenizer, 512)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "q9hGOXhcfrs4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9hGOXhcfrs4",
    "outputId": "a23c72ff-3f48-4c86-df9a-92a45dd51550"
   },
   "outputs": [],
   "source": [
    "def train_custom_model(model, epochs, dataloader):\n",
    "    criterion = nn.BCELoss() ## If required define your own criterion\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataloader: \n",
    "            targets = np.array(batch['label'])\n",
    "            targets = torch.tensor(np.expand_dims(targets,axis=1)).float().cuda()\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].cuda()\n",
    "            attention_mask = batch['attention_mask'].cuda()\n",
    "            outputs = model(input_ids.cuda(), attention_mask.cuda())\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch: \" + str(epoch) + \" Loss: \" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "qVWM7p9W7FkT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVWM7p9W7FkT",
    "outputId": "b634ef79-ffba-46d9-d173-cf325c445dd6"
   },
   "outputs": [],
   "source": [
    "def predict_custom(model, df):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for idx, row in df.iterrows():\n",
    "            input_text = row['Review']\n",
    "            encoding = tokenizer(input_text, add_special_tokens=True, max_length = 512, padding='max_length', truncation=True, return_tensors='pt')\n",
    "            input_ids = encoding['input_ids'].cuda()\n",
    "            attention_mask = encoding['attention_mask'].cuda()\n",
    "            prediction = model(encoding['input_ids'].cuda(), encoding['attention_mask'].cuda())\n",
    "            predictions.append(1 if prediction > 0.5 else 0)\n",
    "            labels.append(convert_lbl_to_int(row['Sentiment']))\n",
    "\n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "151ed761-27be-4990-942f-841d0b741037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_custom_model(model, train_df, test_df):\n",
    "    train_predictions, train_labels = predict_custom(model, train_df)\n",
    "    test_predictions, test_labels = predict_custom(model, test_df)\n",
    "    return f1_score(train_labels, train_predictions, average='micro'), f1_score(test_labels, test_predictions, average='micro')\n",
    "    \n",
    "# print(score_custom_model(model, train_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bb3b666-1ec1-41f8-b58f-ae6d265b533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_all_probe_models(dataloader, train_df, test_df, epochs):\n",
    "    model_scores = []\n",
    "    for n in range(1,12):\n",
    "        print(\"N: \" + str(n))\n",
    "        model = get_custom_bert_model(n)\n",
    "        train_custom_model(model, epochs, dataloader)\n",
    "        train_f1, test_f1 = score_custom_model(model, train_df, test_df)\n",
    "        model_scores.append([n, train_f1, test_f1])\n",
    "\n",
    "    return model_scores        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a1949ee-a200-460d-a868-68e3a313b19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 1\n",
      "Epoch: 0 Loss: tensor(0.6710, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.4555, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.4637, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.3358, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4363, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "N: 2\n",
      "Epoch: 0 Loss: tensor(0.5693, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.4542, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.4242, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4298, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.5534, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "N: 3\n",
      "Epoch: 0 Loss: tensor(0.6479, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.5939, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.6187, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4592, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4384, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "N: 4\n",
      "Epoch: 0 Loss: tensor(0.6714, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.5221, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.3790, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.4346, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4397, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "N: 5\n",
      "Epoch: 0 Loss: tensor(0.6731, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.5771, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.4684, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.3664, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.3709, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "N: 6\n",
      "Epoch: 0 Loss: tensor(0.7135, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.5781, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.6103, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.3371, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4038, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "N: 7\n",
      "Epoch: 0 Loss: tensor(0.6633, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.6115, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.4207, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.3737, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.3468, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "N: 8\n",
      "Epoch: 0 Loss: tensor(0.4205, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.4848, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.3525, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.3812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.3500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "N: 9\n",
      "Epoch: 0 Loss: tensor(0.5791, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.4315, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.2572, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.3580, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.4210, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "N: 10\n",
      "Epoch: 0 Loss: tensor(0.4242, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.2577, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.2704, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.3307, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.2216, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "N: 11\n",
      "Epoch: 0 Loss: tensor(0.2703, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 1 Loss: tensor(0.3646, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 2 Loss: tensor(0.3337, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 3 Loss: tensor(0.3272, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch: 4 Loss: tensor(0.3002, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_scores = score_all_probe_models(dataloader, train_data, test_data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b18569d-1d33-4c52-bda4-7a0560867f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0.845125, 0.8045], [2, 0.80125, 0.7555], [3, 0.79675, 0.7605], [4, 0.83325, 0.7925], [5, 0.817125, 0.783], [6, 0.820625, 0.787], [7, 0.823625, 0.8015], [8, 0.86125, 0.8125], [9, 0.87175, 0.846], [10, 0.88475, 0.8555], [11, 0.889875, 0.856]]\n"
     ]
    }
   ],
   "source": [
    "print(model_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8f63b-329d-4066-b72b-2354e3efc9e2",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b4c0615b-f984-42c6-8399-9978804b5310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2c1b985c-3ce7-41f2-90cb-a4a8059794d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "BertModel                                               --\n",
       "â”œâ”€BertEmbeddings: 1-1                                   --\n",
       "â”‚    â””â”€Embedding: 2-1                                   23,440,896\n",
       "â”‚    â””â”€Embedding: 2-2                                   393,216\n",
       "â”‚    â””â”€Embedding: 2-3                                   1,536\n",
       "â”‚    â””â”€LayerNorm: 2-4                                   1,536\n",
       "â”‚    â””â”€Dropout: 2-5                                     --\n",
       "â”œâ”€BertEncoder: 1-2                                      --\n",
       "â”‚    â””â”€ModuleList: 2-6                                  --\n",
       "â”‚    â”‚    â””â”€BertLayer: 3-1                              7,087,872\n",
       "â”‚    â”‚    â””â”€BertLayer: 3-2                              7,087,872\n",
       "â”‚    â”‚    â””â”€BertLayer: 3-3                              7,087,872\n",
       "â”‚    â”‚    â””â”€BertLayer: 3-4                              7,087,872\n",
       "â”‚    â”‚    â””â”€BertLayer: 3-5                              7,087,872\n",
       "â”‚    â”‚    â””â”€BertLayer: 3-6                              7,087,872\n",
       "â”‚    â”‚    â””â”€BertLayer: 3-7                              7,087,872\n",
       "â”‚    â”‚    â””â”€BertLayer: 3-8                              7,087,872\n",
       "â”‚    â”‚    â””â”€BertLayer: 3-9                              7,087,872\n",
       "â”‚    â”‚    â””â”€BertLayer: 3-10                             7,087,872\n",
       "â”‚    â”‚    â””â”€BertLayer: 3-11                             7,087,872\n",
       "â”‚    â”‚    â””â”€BertLayer: 3-12                             7,087,872\n",
       "â”œâ”€BertPooler: 1-3                                       --\n",
       "â”‚    â””â”€Linear: 2-7                                      590,592\n",
       "â”‚    â””â”€Tanh: 2-8                                        --\n",
       "================================================================================\n",
       "Total params: 109,482,240\n",
       "Trainable params: 109,482,240\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0c58c62b-6c11-4810-bd52-b3d58aa7f853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "CustomBERTModel                                    [64, 1]                   --\n",
       "â”œâ”€BertEmbeddings: 1-1                              [64, 512, 768]            --\n",
       "â”‚    â””â”€Embedding: 2-1                              [64, 512, 768]            23,440,896\n",
       "â”‚    â””â”€Embedding: 2-2                              [64, 512, 768]            1,536\n",
       "â”‚    â””â”€Embedding: 2-3                              [1, 512, 768]             393,216\n",
       "â”‚    â””â”€LayerNorm: 2-4                              [64, 512, 768]            1,536\n",
       "â”‚    â””â”€Dropout: 2-5                                [64, 512, 768]            --\n",
       "â”œâ”€ModuleList: 1-2                                  --                        --\n",
       "â”‚    â””â”€BertLayer: 2-6                              [64, 512, 768]            --\n",
       "â”‚    â”‚    â””â”€BertAttention: 3-1                     [64, 512, 768]            2,363,904\n",
       "â”‚    â”‚    â””â”€BertIntermediate: 3-2                  [64, 512, 3072]           2,362,368\n",
       "â”‚    â”‚    â””â”€BertOutput: 3-3                        [64, 512, 768]            2,361,600\n",
       "â”œâ”€Linear: 1-3                                      [64, 512, 256]            196,864\n",
       "â”œâ”€Linear: 1-4                                      [64, 512, 1]              257\n",
       "â”œâ”€Flatten: 1-5                                     [64, 512]                 --\n",
       "â”œâ”€Linear: 1-6                                      [64, 1]                   513\n",
       "â”œâ”€Sigmoid: 1-7                                     [64, 1]                   --\n",
       "====================================================================================================\n",
       "Total params: 31,122,690\n",
       "Trainable params: 31,122,690\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.97\n",
       "====================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 2889.09\n",
       "Params size (MB): 124.49\n",
       "Estimated Total Size (MB): 3013.58\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, [1, 47])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27350ee-fca8-4e35-bfd2-3614e3df7e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
