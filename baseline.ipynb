{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f343ad35-e195-4859-a3a7-35e4120d1b69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f343ad35-e195-4859-a3a7-35e4120d1b69",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "f40141ba-efe8-4d3b-eedf-b7d49f910716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install transformers\n",
        "# !pip install numpy==1.26.0\n",
        "# !pip install tensorflow[and-cuda]\n",
        "# !pip install torch torchvision torchaudio\n",
        "# !pip install --upgrade ipywidgets\n",
        "# !pip install tf-keras\n",
        "# !pip install pandas\n",
        "# !pip install scikit-learn\n",
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2962b9d0-ba93-4ffa-bf14-18aa63fedea6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2962b9d0-ba93-4ffa-bf14-18aa63fedea6",
        "outputId": "e4a7ab32-5025-4b19-db61-b201c1be7e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar  9 04:02:53 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/avyas21/interpretablellm.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-j8_3zq1UT6",
        "outputId": "dc332bd0-9162-49d3-90a9-409850156e41"
      },
      "id": "n-j8_3zq1UT6",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'interpretablellm'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 61 (delta 22), reused 33 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (61/61), 6.46 MiB | 13.96 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd interpretablellm\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srClFliF1d4O",
        "outputId": "496da933-3eb7-485b-f1cd-ae95afcfc6b8"
      },
      "id": "srClFliF1d4O",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/interpretablellm\n",
            "baseline.ipynb\tbaseline_prompt.txt  data  README.md  setup_dataset.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b82dd9f-e6d6-46ac-9843-ca25199683dc",
      "metadata": {
        "id": "9b82dd9f-e6d6-46ac-9843-ca25199683dc"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4d09ed15-aedc-4fc2-818f-a72d9d98c52f",
      "metadata": {
        "id": "4d09ed15-aedc-4fc2-818f-a72d9d98c52f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b76f9c22-366a-4a15-a179-4c5383ebc244",
      "metadata": {
        "id": "b76f9c22-366a-4a15-a179-4c5383ebc244"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"data/train_data.csv\")\n",
        "test_data = pd.read_csv(\"data/test_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "42f93876-e2bf-4b48-b96e-49f03c8593b2",
      "metadata": {
        "id": "42f93876-e2bf-4b48-b96e-49f03c8593b2"
      },
      "outputs": [],
      "source": [
        "POSITIVE_WORDS = [\"positive\", \"great\", \"good\", \"happy\", \"amazing\", \"fantastic\", \"yes\"]\n",
        "NEGATIVE_WORDS = [\"negative\", \"bad\", \"sad\", \"terrible\", \"horrible\", \"no\", \"critical\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "48213dc3-68d1-4b8b-a454-ec5deed1ee28",
      "metadata": {
        "id": "48213dc3-68d1-4b8b-a454-ec5deed1ee28"
      },
      "outputs": [],
      "source": [
        "def convert_lbl_to_int(label):\n",
        "    if label.lower() in POSITIVE_WORDS:\n",
        "        return 1\n",
        "    if label.lower() in NEGATIVE_WORDS:\n",
        "        return 0\n",
        "    return -1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c594c372-0387-4956-b9e6-a362de13ab1b",
      "metadata": {
        "id": "c594c372-0387-4956-b9e6-a362de13ab1b"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dcc1073e-f664-4053-a2a0-6a866a8ba2b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcc1073e-f664-4053-a2a0-6a866a8ba2b0",
        "outputId": "72b8099c-16ff-4eb4-8445-860c0191f8e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n",
        "from transformers import BertModel, BertTokenizer, BertForSequenceClassification, BertConfig\n",
        "from transformers import pipeline\n",
        "from sklearn.metrics import f1_score\n",
        "from torchinfo import summary\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "04d9d4b2-68ac-433e-933f-407c97a5807b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04d9d4b2-68ac-433e-933f-407c97a5807b",
        "outputId": "7023749b-0fa8-4b8d-d606-27252a1d8d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given a book review, classify it as expressing a positive or negative sentiment.\n",
            "Review: Test Prompt\n",
            "This review is either positive or negative sentiment. If one had to chosen, the sentiment in the review is [MASK].\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def get_prompt(review):\n",
        "  with open(\"baseline_prompt.txt\", \"r\") as file:\n",
        "    prompt = file.read()\n",
        "  prompt = prompt.replace(\"<REVIEW>\", review)\n",
        "  return prompt\n",
        "\n",
        "print(get_prompt(\"Test Prompt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "943dccdc-d64d-438c-8285-42ae4cac65aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447,
          "referenced_widgets": [
            "c34cc6d0ecb54fcaa768fa965a41ae90",
            "0d8f80487e244e34973a7277a76fa84c",
            "e43a335e914a45a1abb80165c0390bcc",
            "0b03169a08334b42ba0faabfc4e1788a",
            "4fffe7551f1e40e28bb4682aa702df64",
            "2fec4aa75d574dff99ad471d44a1f026",
            "d200a1f539944c25a09b6687773b9e13",
            "a3d510a9fcf34a16a3215a0b6e8b2d2f",
            "61edd6575d2c40a0802a67b7b2ff9e4b",
            "fc546c1f05e5456091587903ede5ee34",
            "6153c69fe93d4621b0762cd538f1d9bc",
            "0f9fb3289d2b46d984d78bbf4840333c",
            "43dc7aed2c6d48aa87567b14db9800e8",
            "6fd658a282a84394a5c57cd904dac2cb",
            "ab7dec18a21146b1bc6f8d608ccbc8b2",
            "7d2d2853d5754cfdbfc5958e8f93bd55",
            "bfba79af3c8e4a1388d7158e776060fd",
            "307fa19c980e4843a685d0882cc1499d",
            "7aaaeca490e744d79c8e50f320e16220",
            "47ce46e41422457698aaf8b060cc0c06",
            "b43985336c8c4097b6617f3bd08e84ed",
            "04d3af5cb32740b7b6e3d4eb3e64f9fa",
            "9a39665c405c4f1a91fa53e1d15012c9",
            "26db57945c1c4ba8adbc0d397409ecca",
            "677fa7f8ee4c48569450d93dd18e2692",
            "1cf065cc26ee4d4bbec398d9da191c61",
            "1dfd903bcde34aa58e3693e9c0d601ec",
            "4f9911c8bf6a4145b5dbd511d57c0258",
            "ebd1a5396ec74419a4a74b93ff7e4f98",
            "e746f9bab8e6484193ece0f8d431660e",
            "440e232b382f456587540e812d0cc1e8",
            "2fb1c703cebd4f769543be9356f8978f",
            "87c191c6a6a045ee9deef87390083954",
            "17a045610272481fb0240283bf7e570d",
            "810dc92e12d14a9a8399578f51bba260",
            "132537527d7245b884343a724ad49c69",
            "f02dc5515dbe44e58a124e3910290b95",
            "1ca7180c5ce94646952d3d1a1dff5079",
            "9b9ebfed15254f1aacc686cf5d678334",
            "8404f9c129d54c1581b0135fbf1c0099",
            "569c9b9ec24d4a90bdcd024df49af985",
            "9eaff47ccf144e4987ba2fd4a5a946a7",
            "c4198feeea9a41aca81444efcea7f31c",
            "86eb1a8901aa4844918266ba956fff9b",
            "85dff2268762428ea8c5c66ed84c02de",
            "f63515fba5424c79a1549c1f14e41a9d",
            "d239ec8ed6ae473fbaead8e0dc3edde3",
            "38fd204428254c609671dd1422037bdf",
            "3daea2f3157649ffbc5fb6352a443e1e",
            "aee9590e58a0474d9dfd2a0169b5621d",
            "82f0a1d8502841e8a6d453fe0601b419",
            "f63efe2b2469465eade49a15b5c7bf6c",
            "4a5ff22b8f724ae4bcdf5b74fedc26c9",
            "6c21c1a3e98f458fa234ca77a3e143f8",
            "2125b7ba262847beb78269fbab59d807"
          ]
        },
        "id": "943dccdc-d64d-438c-8285-42ae4cac65aa",
        "outputId": "e3b41f95-bcd4-4465-f75c-1a7cb7b82628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c34cc6d0ecb54fcaa768fa965a41ae90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f9fb3289d2b46d984d78bbf4840333c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a39665c405c4f1a91fa53e1d15012c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17a045610272481fb0240283bf7e570d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85dff2268762428ea8c5c66ed84c02de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Load the BERT model and tokenizer\n",
        "baseline_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "baseline_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "baseline_unmasker = pipeline('fill-mask', model='bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "36e84017-3c95-4195-a64e-872de86aa27d",
      "metadata": {
        "id": "36e84017-3c95-4195-a64e-872de86aa27d"
      },
      "outputs": [],
      "source": [
        "def predict(review, unmasker):\n",
        "  prompt = get_prompt(review)\n",
        "  predictions = unmasker(prompt)\n",
        "  valid_predictions = POSITIVE_WORDS + NEGATIVE_WORDS\n",
        "\n",
        "  for prediction in predictions:\n",
        "    if(prediction['token_str'] in valid_predictions):\n",
        "      return prediction['token_str']\n",
        "\n",
        "  for prediction in predictions:\n",
        "    print(prediction['token_str'])\n",
        "\n",
        "  sentiment = [\"positive\", \"negative\"]\n",
        "  #If not found, lets predict random\n",
        "  return \"NOT FOUND\" #random.choice(sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3efd9030-e3ac-4c20-92b5-a82df8b63a4b",
      "metadata": {
        "id": "3efd9030-e3ac-4c20-92b5-a82df8b63a4b"
      },
      "outputs": [],
      "source": [
        "def predict_baseline(df, model, tokenizer, unmasker):\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    for idx, row in df.iterrows():\n",
        "        input_text = row['Review']\n",
        "        prediction = predict(input_text, unmasker)\n",
        "        predictions.append(convert_lbl_to_int(prediction))\n",
        "        labels.append(convert_lbl_to_int(row['Sentiment']))\n",
        "    return predictions, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9DhDookCV4cA",
      "metadata": {
        "id": "9DhDookCV4cA"
      },
      "outputs": [],
      "source": [
        "def score_baseline(baseline_model, df, baseline_tokenizer, baseline_unmasker):\n",
        "    predictions, labels = predict_baseline(df, baseline_model, baseline_tokenizer, baseline_unmasker)\n",
        "    values, counts = np.unique(np.array(predictions), return_counts=True)\n",
        "\n",
        "    for v, c in zip(values, counts):\n",
        "        print(f\"Value: {v}, Count: {c}\")\n",
        "\n",
        "    return f1_score(labels, predictions, average='micro')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "85f05cf6-0511-4f27-90fc-207b5e4678ef",
      "metadata": {
        "id": "85f05cf6-0511-4f27-90fc-207b5e4678ef",
        "outputId": "1e14c547-ac57-4d56-91d2-b461c92745c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3fd9da737e0a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_baseline_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_unmasker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_baseline_f1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-85bf27f5dc6a>\u001b[0m in \u001b[0;36mscore_baseline\u001b[0;34m(baseline_model, df, baseline_tokenizer, baseline_unmasker)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_unmasker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_unmasker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-b781ced9ccdb>\u001b[0m in \u001b[0;36mpredict_baseline\u001b[0;34m(df, model, tokenizer, unmasker)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munmasker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_lbl_to_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_lbl_to_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-92679eb72f8e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(review, unmasker)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munmasker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munmasker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mvalid_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOSITIVE_WORDS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mNEGATIVE_WORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtoken_str\u001b[0m\u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto\u001b[0m \u001b[0mreplace\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \"\"\"\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1360\u001b[0m             )\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Framework {self.framework} is not supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m_ensure_tensor_on_device\u001b[0;34m(self, inputs, device)\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             return ModelOutput(\n\u001b[0;32m-> 1170\u001b[0;31m                 \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m             )\n\u001b[1;32m   1172\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             return ModelOutput(\n\u001b[0;32m-> 1170\u001b[0;31m                 \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m             )\n\u001b[1;32m   1172\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m_ensure_tensor_on_device\u001b[0;34m(self, inputs, device)\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_baseline_f1 = score_baseline(baseline_model, train_data, baseline_tokenizer, baseline_unmasker)\n",
        "print(train_baseline_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0f61be6-17ee-42cd-ab37-024e26f63319",
      "metadata": {
        "id": "d0f61be6-17ee-42cd-ab37-024e26f63319"
      },
      "outputs": [],
      "source": [
        "test_baseline_f1 = score_baseline(baseline_model, test_data, baseline_tokenizer, baseline_unmasker)\n",
        "print(test_baseline_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89b6d9a2-b1cc-438c-bdf2-7cddba7ce1a7",
      "metadata": {
        "id": "89b6d9a2-b1cc-438c-bdf2-7cddba7ce1a7"
      },
      "source": [
        "## Probe Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "hs9tJr6xUte3",
      "metadata": {
        "id": "hs9tJr6xUte3"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from transformers import AutoTokenizer, BertModel\n",
        "import pandas as pd\n",
        "\n",
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self, n, randomized=False, linear_1 = None, linear_2 = None):\n",
        "        super(CustomBERTModel, self).__init__()\n",
        "        if randomized:\n",
        "          config = BertConfig()\n",
        "          self.bert = BertModel(config).to(torch.device(\"cuda\"))\n",
        "        else:\n",
        "          self.bert=  BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.bert.encoder.layer = nn.ModuleList(self.bert.encoder.layer[:n])\n",
        "\n",
        "        # Reinitialize weights for each layer in the encoder\n",
        "        for layer in self.bert.encoder.layer:\n",
        "            for module in layer.modules():\n",
        "              for mod in module.modules():\n",
        "                  if isinstance(mod, (nn.Linear, nn.Conv2d)):\n",
        "                      # Reinitialize weights for linear and convolution layers\n",
        "                      # print(\"Before Randomization:\", mod.weight)\n",
        "                      nn.init.xavier_uniform_(mod.weight)\n",
        "                      # print(\"After Randomization:\", mod.weight)\n",
        "                      if mod.bias is not None:\n",
        "                          nn.init.zeros_(mod.bias)\n",
        "                  elif isinstance(mod, nn.LayerNorm):\n",
        "                      # Reinitialize LayerNorm layers\n",
        "                      nn.init.ones_(mod.weight)\n",
        "                      nn.init.zeros_(mod.bias)\n",
        "                  # print(\"Mod\")\n",
        "                  # print(mod)\n",
        "              #print(module)\n",
        "            #print(layer)\n",
        "\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        ### New layers:\n",
        "\n",
        "        if linear_1 is not None:\n",
        "          self.linear_1 = linear_1\n",
        "        else:\n",
        "          self.linear_1 = nn.Linear(768, 256)\n",
        "\n",
        "        if linear_2 is not None:\n",
        "          self.linear_2 = linear_2\n",
        "        else:\n",
        "          self.linear_2 = nn.Linear(256, 1)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "        output = self.bert(input_ids=ids, attention_mask=mask, output_hidden_states=True)\n",
        "\n",
        "        linear1_output = self.linear_1(output.last_hidden_state[:,0,:])\n",
        "        linear2_output = self.linear_2(self.dropout(linear1_output))\n",
        "        sigmoid_output = self.sigmoid(linear2_output)\n",
        "        return sigmoid_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6a62027a-0f6f-4059-a36d-51ef161bfdc8",
      "metadata": {
        "id": "6a62027a-0f6f-4059-a36d-51ef161bfdc8"
      },
      "outputs": [],
      "source": [
        "def get_custom_bert_model(num_bert_layers, toggle):\n",
        "  gpu_available = torch.cuda.is_available()\n",
        "  model = CustomBERTModel(num_bert_layers, toggle)\n",
        "  if gpu_available:\n",
        "    return model.to(torch.device(\"cuda\"))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3c3e9cee-6067-4933-ab0a-2a8de05ccc0b",
      "metadata": {
        "id": "3c3e9cee-6067-4933-ab0a-2a8de05ccc0b"
      },
      "outputs": [],
      "source": [
        "baseline_model = get_custom_bert_model(2, True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(baseline_model.linear_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qf2h0cuD_gl",
        "outputId": "186adb11-0064-4efa-e85f-e754e9870c11"
      },
      "id": "_Qf2h0cuD_gl",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=768, out_features=256, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ZuLuCEEqWxpF",
      "metadata": {
        "id": "ZuLuCEEqWxpF"
      },
      "outputs": [],
      "source": [
        "def get_inputs_labels(df):\n",
        "    inputs = []\n",
        "    labels = []\n",
        "    for idx, row in train_data.iterrows():\n",
        "        input_text = row['Review']\n",
        "        inputs.append(input_text)\n",
        "        labels.append(1 if row['Sentiment'] == 'positive' else 0)\n",
        "    return inputs, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "485XykGLie_x",
      "metadata": {
        "id": "485XykGLie_x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "L53zFoGWaT0q",
      "metadata": {
        "id": "L53zFoGWaT0q"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "inputs, labels = get_inputs_labels(train_data)\n",
        "dataset = TextDataset(inputs, labels, tokenizer, 512)\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "qVWM7p9W7FkT",
      "metadata": {
        "id": "qVWM7p9W7FkT"
      },
      "outputs": [],
      "source": [
        "def predict(model, df):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    gpu_available = torch.cuda.is_available()\n",
        "    with torch.no_grad():\n",
        "        for idx, row in df.iterrows():\n",
        "            input_text = row['Review']\n",
        "            encoding = tokenizer(input_text, add_special_tokens=True, max_length = 512, padding='max_length', truncation=True, return_tensors='pt')\n",
        "            if gpu_available:\n",
        "              input_ids = encoding['input_ids'].cuda()\n",
        "              attention_mask = encoding['attention_mask'].cuda()\n",
        "              prediction = model(encoding['input_ids'].cuda(), encoding['attention_mask'].cuda())\n",
        "            else:\n",
        "              input_ids = encoding['input_ids']\n",
        "              attention_mask = encoding['attention_mask']\n",
        "              prediction = model(encoding['input_ids'], encoding['attention_mask'])\n",
        "            predictions.append(1 if prediction > 0.5 else 0)\n",
        "            labels.append(convert_lbl_to_int(row['Sentiment']))\n",
        "\n",
        "    return predictions, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "151ed761-27be-4990-942f-841d0b741037",
      "metadata": {
        "id": "151ed761-27be-4990-942f-841d0b741037"
      },
      "outputs": [],
      "source": [
        "def score_model(model, train_df, test_df):\n",
        "    train_f1 = None\n",
        "    test_f1 = None\n",
        "\n",
        "    if train_df is not None:\n",
        "        train_predictions, train_labels = predict(model, train_df)\n",
        "        train_f1 = f1_score(train_labels, train_predictions, average='micro')\n",
        "\n",
        "    if test_df is not None:\n",
        "        test_predictions, test_labels = predict(model, test_df)\n",
        "        test_f1 = f1_score(test_labels, test_predictions, average='micro')\n",
        "\n",
        "    return train_f1, test_f1\n",
        "\n",
        "# print(score_custom_model(model, train_data, test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "6a39bd50-3426-4627-8071-f22a47a73545",
      "metadata": {
        "id": "6a39bd50-3426-4627-8071-f22a47a73545"
      },
      "outputs": [],
      "source": [
        "def get_loss(model, df):\n",
        "    inputs, labels = get_inputs_labels(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGn4ZHtQ3Xum",
        "outputId": "c1383764-3f57-4eb5-c2bf-61f327f715c7"
      },
      "id": "ZGn4ZHtQ3Xum",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "q9hGOXhcfrs4",
      "metadata": {
        "id": "q9hGOXhcfrs4"
      },
      "outputs": [],
      "source": [
        "def train_model(model, epochs, dataloader, train_df, learning_rate = 1e-3, calc_train_f1 = True):\n",
        "    criterion = nn.BCELoss() ## If required define your own criterion\n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = learning_rate)\n",
        "    gpu_available = torch.cuda.is_available()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        i = 0\n",
        "        for batch in dataloader:\n",
        "            targets = np.array(batch['label'])\n",
        "            targets = torch.tensor(np.expand_dims(targets,axis=1)).float()\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch['input_ids']\n",
        "            attention_mask = batch['attention_mask']\n",
        "\n",
        "            if gpu_available:\n",
        "              targets = targets.cuda()\n",
        "              input_ids = input_ids.cuda()\n",
        "              attention_mask = attention_mask.cuda()\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            # if i % 20 == 0:\n",
        "            #   print(loss)\n",
        "            optimizer.step()\n",
        "            i += 1\n",
        "\n",
        "        if calc_train_f1:\n",
        "          train_f1, _ = score_model(model, train_df, None)\n",
        "          print(\"Epoch: \" + str(epoch) + \" F1: \" + str(train_f1) + \" LOSS: \" + str(loss))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(baseline_model, 10, dataloader, train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcswQWUFrPEW",
        "outputId": "b663958a-4480-4bd5-a153-8cfb0391fe16"
      },
      "id": "AcswQWUFrPEW",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7615, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.9821, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6292, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7170, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6782, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7056, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6367, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7618, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7097, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6708, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6675, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5491, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6323, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 0 F1: 0.64725 LOSS: tensor(0.7356, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5937, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6100, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6302, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6193, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5501, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6210, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6340, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6194, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7346, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6282, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6512, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5590, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.6475 LOSS: tensor(0.6097, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5724, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6352, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6916, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5158, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6631, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5549, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5892, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5652, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6317, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5312, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6029, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5604, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5621, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.70175 LOSS: tensor(0.5253, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6251, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5578, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6108, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6028, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5694, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6714, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5595, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6511, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6397, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5969, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6477, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5796, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5345, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.7225 LOSS: tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5643, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5733, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5995, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4362, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5557, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6412, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5232, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5604, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5726, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5922, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6226, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5406, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.73 LOSS: tensor(0.5446, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7115, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5503, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4513, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5661, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6075, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4966, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6707, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5487, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6975, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5202, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6646, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7503, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4964, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.669125 LOSS: tensor(0.5960, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5745, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6063, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6676, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6498, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6353, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5150, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5432, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7459, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4675, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5175, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4788, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5446, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.731625 LOSS: tensor(0.5298, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5747, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5049, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5710, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5629, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5107, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4334, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5205, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4137, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6231, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6998, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5248, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6979, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.638 LOSS: tensor(0.7044, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6087, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7730, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5389, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5646, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.7900, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4802, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5816, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5557, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6173, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6102, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5373, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6615, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.754 LOSS: tensor(0.5724, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5564, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5651, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5373, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5855, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5174, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4987, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4422, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5045, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6247, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5480, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5251, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5343, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5457, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.650375 LOSS: tensor(0.5714, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, test_f1 = score_model(baseline_model, None, test_data)\n",
        "print(\"TEST F1: \" + str(test_f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLqEBas5Af88",
        "outputId": "d3a20986-b09b-4c71-d501-9a00eb1f4b29"
      },
      "id": "QLqEBas5Af88",
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST F1: 0.6005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_all_randomized_models(dataloader, train_df, test_df, epochs, max_n, learning_rate = 1e-3):\n",
        "    model_scores = []\n",
        "    for n in range(3,max_n + 1):\n",
        "        print(\"N: \" + str(n))\n",
        "        model = get_custom_bert_model(n, True)\n",
        "        train_model(model, epochs, dataloader, train_df, learning_rate)\n",
        "        _, test_f1 = score_model(model, None, test_df)\n",
        "        print(\"TEST F1: \" + str(test_f1))\n",
        "        model_scores.append([n, test_f1])\n",
        "\n",
        "    return model_scores"
      ],
      "metadata": {
        "id": "q8q83o7zBZly"
      },
      "id": "q8q83o7zBZly",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "2a1949ee-a200-460d-a868-68e3a313b19e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a1949ee-a200-460d-a868-68e3a313b19e",
        "outputId": "4b81d52e-b215-464a-9338-c830113ac827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N: 3\n",
            "Epoch: 0 F1: 0.619625 LOSS: tensor(0.6610, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.69375 LOSS: tensor(0.6401, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.670375 LOSS: tensor(0.5833, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.685875 LOSS: tensor(0.6176, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.66575 LOSS: tensor(0.6373, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.694 LOSS: tensor(0.5220, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.71 LOSS: tensor(0.4995, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.7255 LOSS: tensor(0.5419, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.6955 LOSS: tensor(0.5208, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.747625 LOSS: tensor(0.5655, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "TEST F1: 0.685\n",
            "N: 4\n",
            "Epoch: 0 F1: 0.631375 LOSS: tensor(0.6895, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.652125 LOSS: tensor(0.6138, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.668 LOSS: tensor(0.6527, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.636625 LOSS: tensor(0.6110, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.614625 LOSS: tensor(0.5310, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.72425 LOSS: tensor(0.6641, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.71575 LOSS: tensor(0.5071, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.73425 LOSS: tensor(0.5072, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.690625 LOSS: tensor(0.5398, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.696375 LOSS: tensor(0.5248, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "TEST F1: 0.6665\n",
            "N: 5\n",
            "Epoch: 0 F1: 0.649875 LOSS: tensor(0.7079, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.6915 LOSS: tensor(0.5972, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.718625 LOSS: tensor(0.5620, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.68925 LOSS: tensor(0.4737, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.73425 LOSS: tensor(0.5602, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.637375 LOSS: tensor(0.5779, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.668375 LOSS: tensor(0.6238, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.672625 LOSS: tensor(0.4808, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.729125 LOSS: tensor(0.5243, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.728375 LOSS: tensor(0.6318, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "TEST F1: 0.6955\n",
            "N: 6\n",
            "Epoch: 0 F1: 0.64725 LOSS: tensor(0.6687, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.677 LOSS: tensor(0.5973, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.701375 LOSS: tensor(0.5755, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.64175 LOSS: tensor(0.7183, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.69675 LOSS: tensor(0.5526, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.722 LOSS: tensor(0.6047, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.687 LOSS: tensor(0.4548, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.7295 LOSS: tensor(0.5125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.72 LOSS: tensor(0.5261, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.659 LOSS: tensor(0.5603, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "TEST F1: 0.601\n",
            "N: 7\n",
            "Epoch: 0 F1: 0.584875 LOSS: tensor(0.7218, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.6335 LOSS: tensor(0.5676, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.680875 LOSS: tensor(0.6577, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.691125 LOSS: tensor(0.5591, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.65125 LOSS: tensor(0.5942, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.69125 LOSS: tensor(0.5202, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.666 LOSS: tensor(0.6411, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.72325 LOSS: tensor(0.5809, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.72575 LOSS: tensor(0.5481, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.711625 LOSS: tensor(0.6060, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "TEST F1: 0.6485\n",
            "N: 8\n",
            "Epoch: 0 F1: 0.651875 LOSS: tensor(0.5914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.61525 LOSS: tensor(0.5523, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.692625 LOSS: tensor(0.6338, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.696125 LOSS: tensor(0.6014, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.680375 LOSS: tensor(0.6225, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.6705 LOSS: tensor(0.5515, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.714375 LOSS: tensor(0.5454, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.713625 LOSS: tensor(0.5533, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.689 LOSS: tensor(0.5509, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.658125 LOSS: tensor(0.6380, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "TEST F1: 0.593\n",
            "N: 9\n",
            "Epoch: 0 F1: 0.64175 LOSS: tensor(0.7151, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.616 LOSS: tensor(0.5832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.668875 LOSS: tensor(0.5145, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.643125 LOSS: tensor(0.6379, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.687875 LOSS: tensor(0.6094, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.655875 LOSS: tensor(0.5155, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.707375 LOSS: tensor(0.6139, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.709875 LOSS: tensor(0.5990, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.710375 LOSS: tensor(0.5206, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.711875 LOSS: tensor(0.6401, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "TEST F1: 0.643\n",
            "N: 10\n",
            "Epoch: 0 F1: 0.6145 LOSS: tensor(0.6537, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.65525 LOSS: tensor(0.6610, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.680875 LOSS: tensor(0.5738, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.6885 LOSS: tensor(0.5834, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.68125 LOSS: tensor(0.6036, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.6725 LOSS: tensor(0.5055, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.69475 LOSS: tensor(0.5451, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.668625 LOSS: tensor(0.7499, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.709125 LOSS: tensor(0.5652, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.71325 LOSS: tensor(0.7973, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "TEST F1: 0.6445\n",
            "N: 11\n",
            "Epoch: 0 F1: 0.586 LOSS: tensor(0.6256, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.649375 LOSS: tensor(0.6125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.629 LOSS: tensor(0.5881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.670875 LOSS: tensor(0.6254, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.6335 LOSS: tensor(0.6544, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.665375 LOSS: tensor(0.6496, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.654125 LOSS: tensor(0.5884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.685375 LOSS: tensor(0.5742, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.674125 LOSS: tensor(0.6121, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.68675 LOSS: tensor(0.6966, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "TEST F1: 0.631\n",
            "N: 12\n",
            "Epoch: 0 F1: 0.59475 LOSS: tensor(0.6441, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.627 LOSS: tensor(0.6570, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.631625 LOSS: tensor(0.6388, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.638375 LOSS: tensor(0.5732, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.662125 LOSS: tensor(0.6640, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.664125 LOSS: tensor(0.5706, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.6435 LOSS: tensor(0.5988, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.62875 LOSS: tensor(0.6234, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.664125 LOSS: tensor(0.6034, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.638875 LOSS: tensor(0.5518, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "TEST F1: 0.601\n"
          ]
        }
      ],
      "source": [
        "model_scores = score_all_randomized_models(dataloader, train_data, test_data, 10, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "5bb3b666-1ec1-41f8-b58f-ae6d265b533a",
      "metadata": {
        "id": "5bb3b666-1ec1-41f8-b58f-ae6d265b533a"
      },
      "outputs": [],
      "source": [
        "def score_all_probe_models(dataloader, train_df, test_df, epochs, max_n, learning_rate = 1e-3):\n",
        "    model_scores = []\n",
        "    for n in range(1,max_n + 1):\n",
        "        print(\"N: \" + str(n))\n",
        "        model = get_custom_bert_model(n)\n",
        "        train_model(model, epochs, dataloader, train_df, learning_rate)\n",
        "        _, test_f1 = score_model(model, None, test_df)\n",
        "        print(\"TEST F1: \" + str(test_f1))\n",
        "        model_scores.append([n, test_f1])\n",
        "\n",
        "    return model_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scalar Mixing Weights"
      ],
      "metadata": {
        "id": "8lTdl-n_zyXY"
      },
      "id": "8lTdl-n_zyXY"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from transformers import AutoTokenizer, BertModel\n",
        "import pandas as pd\n",
        "\n",
        "class ScalarMixingWeightModel(nn.Module):\n",
        "    def __init__(self, n, i):\n",
        "        super(ScalarMixingWeightModel, self).__init__()\n",
        "\n",
        "        self.bert= BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.bert.encoder.layer = nn.ModuleList(self.bert.encoder.layer[:n])\n",
        "        self.n = n\n",
        "        self.layer_weights = nn.Parameter(torch.ones(self.n))\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "        self.i = i\n",
        "\n",
        "        self.gamma = nn.Parameter(torch.ones(1))\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        ### New layers:\n",
        "        if self.i == 1:\n",
        "          self.linear1 = nn.Linear(768, 1)\n",
        "        elif self.i == 2:\n",
        "          self.linear1 = nn.Linear(768, 384)\n",
        "          self.linear2 = nn.Linear(384, 1)\n",
        "        elif self.i == 3:\n",
        "          self.linear1 = nn.Linear(768, 384)\n",
        "          self.linear2 = nn.Linear(384, 192)\n",
        "          self.linear3 = nn.Linear(192, 1)\n",
        "        elif self.i == 4:\n",
        "          self.linear1 = nn.Linear(768, 384)\n",
        "          self.linear2 = nn.Linear(384, 192)\n",
        "          self.linear3 = nn.Linear(192, 96)\n",
        "          self.linear4 = nn.Linear(96, 1)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "        outputs = self.bert(input_ids=ids, attention_mask=mask, output_hidden_states=True)\n",
        "\n",
        "        hidden_states = outputs.hidden_states[1:1 + self.n]\n",
        "\n",
        "        normalized_weights = self.softmax(self.layer_weights)\n",
        "        scalar_mixing_weight = self.gamma * sum(normalized_weights[i] * hidden_states[i] for i in range(self.n))\n",
        "\n",
        "        if self.i == 1:\n",
        "          linear1_output = self.dropout(self.linear1(scalar_mixing_weight[:, 0, :]))\n",
        "          sigmoid_output = self.sigmoid(linear1_output)\n",
        "        elif self.i == 2:\n",
        "          linear1_output = self.linear1(scalar_mixing_weight[:, 0, :])\n",
        "          linear2_output = self.linear2(self.dropout(linear1_output))\n",
        "          sigmoid_output = self.sigmoid(linear2_output)\n",
        "        elif self.i == 3:\n",
        "          linear1_output = self.linear1(scalar_mixing_weight[:, 0, :])\n",
        "          linear2_output = self.linear2(self.dropout(linear1_output))\n",
        "          linear3_output = self.linear3(self.dropout(linear2_output))\n",
        "          sigmoid_output = self.sigmoid(linear3_output)\n",
        "        elif self.i == 4:\n",
        "          linear1_output = self.linear1(scalar_mixing_weight[:, 0, :])\n",
        "          linear2_output = self.linear2(self.dropout(linear1_output))\n",
        "          linear3_output = self.linear3(self.dropout(linear2_output))\n",
        "          linear4_output = self.linear4(self.dropout(linear3_output))\n",
        "          sigmoid_output = self.sigmoid(linear4_output)\n",
        "\n",
        "        return sigmoid_output\n"
      ],
      "metadata": {
        "id": "Ltfx0_XMzxeh"
      },
      "id": "Ltfx0_XMzxeh",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scalar_mixing_model(num_bert_layers, i):\n",
        "  gpu_available = torch.cuda.is_available()\n",
        "  model = ScalarMixingWeightModel(num_bert_layers, i)\n",
        "\n",
        "  if gpu_available:\n",
        "    return model.to(torch.device(\"cuda\"))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "lGp5exkZ17M_"
      },
      "id": "lGp5exkZ17M_",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = {}\n",
        "for i in range(12,13):\n",
        "  test_scalar = get_scalar_mixing_model(i,1)\n",
        "  train_model(test_scalar, 10, dataloader, train_data, learning_rate = 0.1)\n",
        "  print(i, \":\", test_scalar.layer_weights)\n",
        "  weights[i] = test_scalar.layer_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhSJ9GBk1__M",
        "outputId": "d9185a23-1f07-480b-deba-051d21cd7a3f",
        "collapsed": true
      },
      "id": "uhSJ9GBk1__M",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 F1: 0.8065 LOSS: tensor(0.6056, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.888 LOSS: tensor(0.3546, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.90125 LOSS: tensor(0.4299, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.895125 LOSS: tensor(0.2991, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.906125 LOSS: tensor(0.2043, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.907625 LOSS: tensor(0.4325, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.900625 LOSS: tensor(0.3901, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.9125 LOSS: tensor(0.2068, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.91525 LOSS: tensor(0.2820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.913125 LOSS: tensor(0.1217, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "12 : Parameter containing:\n",
            "tensor([ 1.9658,  2.0972,  0.7196, -1.1301, -1.1111, -0.8035, -0.9748, -1.2555,\n",
            "        -1.0048,  0.0156,  3.5237,  4.3171], device='cuda:0',\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lrs = [0.1, 0.01, 0.001, 0.0001]\n",
        "for lr in lrs:\n",
        "  for i in range(1,5):\n",
        "    test_scalar = get_scalar_mixing_model(2, i)\n",
        "    train_model(test_scalar, 10, dataloader, train_data, learning_rate = lr)\n",
        "    print(\"Learning rate:\", lr, \"Number of layers\", i)"
      ],
      "metadata": {
        "id": "GsEo-F0ghfj8",
        "outputId": "d2ba4cea-9109-49e9-b76e-e43b8ad87fd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GsEo-F0ghfj8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 F1: 0.5 LOSS: tensor(0.6902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.579 LOSS: tensor(0.6880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.747375 LOSS: tensor(0.6665, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.76175 LOSS: tensor(0.4873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.754875 LOSS: tensor(0.4700, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.771375 LOSS: tensor(0.3286, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.817375 LOSS: tensor(0.4258, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.808375 LOSS: tensor(0.3882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.7935 LOSS: tensor(0.6432, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.827375 LOSS: tensor(0.3705, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.1 Number of layers 1\n",
            "Epoch: 0 F1: 0.5 LOSS: tensor(51.5625, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.5 LOSS: tensor(62.5000, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.5 LOSS: tensor(56.2500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.1 Number of layers 2\n",
            "Epoch: 0 F1: 0.5 LOSS: tensor(32.8125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.5 LOSS: tensor(56.2500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.5 LOSS: tensor(42.1875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.5 LOSS: tensor(57.8125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.5 LOSS: tensor(42.1875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.1 Number of layers 3\n",
            "Epoch: 0 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.5 LOSS: tensor(51.5625, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.5 LOSS: tensor(39.0625, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.1 Number of layers 4\n",
            "Epoch: 0 F1: 0.688625 LOSS: tensor(0.6729, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.72625 LOSS: tensor(0.5735, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.7225 LOSS: tensor(0.4890, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.778 LOSS: tensor(0.4555, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.797125 LOSS: tensor(0.4818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.766375 LOSS: tensor(0.5095, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.81625 LOSS: tensor(0.3692, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.81525 LOSS: tensor(0.4498, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.823 LOSS: tensor(0.3185, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.8255 LOSS: tensor(0.4187, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.01 Number of layers 1\n",
            "Epoch: 0 F1: 0.623625 LOSS: tensor(0.5963, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.755375 LOSS: tensor(0.5610, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.773625 LOSS: tensor(0.4210, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.8115 LOSS: tensor(0.4335, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.80525 LOSS: tensor(0.3416, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.8125 LOSS: tensor(0.4147, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.8195 LOSS: tensor(0.4914, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.80625 LOSS: tensor(0.4377, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.719 LOSS: tensor(0.3938, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.80725 LOSS: tensor(0.3015, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.01 Number of layers 2\n",
            "Epoch: 0 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.5 LOSS: tensor(59.3750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.5 LOSS: tensor(43.7500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.5 LOSS: tensor(57.8125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.5 LOSS: tensor(46.8750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.5 LOSS: tensor(65.6250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.01 Number of layers 3\n",
            "Epoch: 0 F1: 0.5 LOSS: tensor(50., device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.5 LOSS: tensor(53.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.5 LOSS: tensor(43.7500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.5 LOSS: tensor(45.3125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.5 LOSS: tensor(48.4375, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.5 LOSS: tensor(54.6875, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.01 Number of layers 4\n",
            "Epoch: 0 F1: 0.622875 LOSS: tensor(0.7243, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.637875 LOSS: tensor(0.6641, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.644875 LOSS: tensor(0.6571, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.66575 LOSS: tensor(0.6701, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.6845 LOSS: tensor(0.6082, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.693125 LOSS: tensor(0.5579, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.714375 LOSS: tensor(0.5850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.734625 LOSS: tensor(0.5675, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.728 LOSS: tensor(0.5235, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.75325 LOSS: tensor(0.5115, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.001 Number of layers 1\n",
            "Epoch: 0 F1: 0.67325 LOSS: tensor(0.6584, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.710625 LOSS: tensor(0.5366, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.751375 LOSS: tensor(0.5209, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.786125 LOSS: tensor(0.4284, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.800375 LOSS: tensor(0.5209, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.7775 LOSS: tensor(0.3774, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.783625 LOSS: tensor(0.4044, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.814875 LOSS: tensor(0.4114, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.784625 LOSS: tensor(0.3569, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.82025 LOSS: tensor(0.4046, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.001 Number of layers 2\n",
            "Epoch: 0 F1: 0.643875 LOSS: tensor(0.6335, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.6025 LOSS: tensor(0.6195, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.75075 LOSS: tensor(0.4377, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.792625 LOSS: tensor(0.3910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.7925 LOSS: tensor(0.3448, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.81275 LOSS: tensor(0.4162, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.81725 LOSS: tensor(0.4785, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.81775 LOSS: tensor(0.5427, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.816375 LOSS: tensor(0.4804, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.74775 LOSS: tensor(0.4635, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.001 Number of layers 3\n",
            "Epoch: 0 F1: 0.599375 LOSS: tensor(0.6650, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.7395 LOSS: tensor(0.5235, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.78475 LOSS: tensor(0.4132, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.763875 LOSS: tensor(0.4276, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.80175 LOSS: tensor(0.4442, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.71925 LOSS: tensor(0.4258, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.8145 LOSS: tensor(0.5349, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.82225 LOSS: tensor(0.5277, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.812875 LOSS: tensor(0.4315, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.813375 LOSS: tensor(0.3786, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.001 Number of layers 4\n",
            "Epoch: 0 F1: 0.499625 LOSS: tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.583 LOSS: tensor(0.6873, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.57775 LOSS: tensor(0.6818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.5655 LOSS: tensor(0.6889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.61075 LOSS: tensor(0.6827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.609375 LOSS: tensor(0.6845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.61575 LOSS: tensor(0.6911, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.619625 LOSS: tensor(0.6795, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.623875 LOSS: tensor(0.6763, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.626625 LOSS: tensor(0.6737, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.0001 Number of layers 1\n",
            "Epoch: 0 F1: 0.62725 LOSS: tensor(0.6907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.63025 LOSS: tensor(0.6799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.656 LOSS: tensor(0.6105, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.665125 LOSS: tensor(0.6588, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.691 LOSS: tensor(0.5975, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.70775 LOSS: tensor(0.5938, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.708 LOSS: tensor(0.6180, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.735 LOSS: tensor(0.5417, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.740875 LOSS: tensor(0.5361, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.755125 LOSS: tensor(0.4723, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.0001 Number of layers 2\n",
            "Epoch: 0 F1: 0.62875 LOSS: tensor(0.6600, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.626875 LOSS: tensor(0.6630, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.647125 LOSS: tensor(0.6467, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.678625 LOSS: tensor(0.5910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.71625 LOSS: tensor(0.5632, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.71625 LOSS: tensor(0.4906, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.766125 LOSS: tensor(0.4897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.747 LOSS: tensor(0.3912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.754 LOSS: tensor(0.5500, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.774375 LOSS: tensor(0.5170, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.0001 Number of layers 3\n",
            "Epoch: 0 F1: 0.519125 LOSS: tensor(0.6764, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1 F1: 0.60725 LOSS: tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 2 F1: 0.645125 LOSS: tensor(0.6653, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 3 F1: 0.6925 LOSS: tensor(0.5769, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 4 F1: 0.747625 LOSS: tensor(0.4810, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 5 F1: 0.74725 LOSS: tensor(0.4977, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 6 F1: 0.77625 LOSS: tensor(0.4830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 7 F1: 0.789 LOSS: tensor(0.4862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 8 F1: 0.79275 LOSS: tensor(0.5131, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 9 F1: 0.799625 LOSS: tensor(0.4610, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Learning rate: 0.0001 Number of layers 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40f8f63b-329d-4066-b72b-2354e3efc9e2",
      "metadata": {
        "id": "40f8f63b-329d-4066-b72b-2354e3efc9e2"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c1b985c-3ce7-41f2-90cb-a4a8059794d6",
      "metadata": {
        "id": "2c1b985c-3ce7-41f2-90cb-a4a8059794d6",
        "outputId": "94e5ebe3-9b8b-4fbe-fb8b-718d9d38212d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "================================================================================\n",
              "Layer (type:depth-idx)                                  Param #\n",
              "================================================================================\n",
              "BertModel                                               --\n",
              "├─BertEmbeddings: 1-1                                   --\n",
              "│    └─Embedding: 2-1                                   (23,440,896)\n",
              "│    └─Embedding: 2-2                                   (393,216)\n",
              "│    └─Embedding: 2-3                                   (1,536)\n",
              "│    └─LayerNorm: 2-4                                   (1,536)\n",
              "│    └─Dropout: 2-5                                     --\n",
              "├─BertEncoder: 1-2                                      --\n",
              "│    └─ModuleList: 2-6                                  --\n",
              "│    │    └─BertLayer: 3-1                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-2                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-3                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-4                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-5                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-6                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-7                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-8                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-9                              (7,087,872)\n",
              "│    │    └─BertLayer: 3-10                             (7,087,872)\n",
              "│    │    └─BertLayer: 3-11                             7,087,872\n",
              "│    │    └─BertLayer: 3-12                             7,087,872\n",
              "├─BertPooler: 1-3                                       --\n",
              "│    └─Linear: 2-7                                      590,592\n",
              "│    └─Tanh: 2-8                                        --\n",
              "================================================================================\n",
              "Total params: 109,482,240\n",
              "Trainable params: 14,766,336\n",
              "Non-trainable params: 94,715,904\n",
              "================================================================================"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(baseline_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c58c62b-6c11-4810-bd52-b3d58aa7f853",
      "metadata": {
        "id": "0c58c62b-6c11-4810-bd52-b3d58aa7f853",
        "outputId": "30c9add2-5227-4935-942a-1a5d847cac67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "===========================================================================\n",
              "Layer (type:depth-idx)                             Param #\n",
              "===========================================================================\n",
              "CustomBERTModel                                    --\n",
              "├─BertEmbeddings: 1-1                              --\n",
              "│    └─Embedding: 2-1                              (23,440,896)\n",
              "│    └─Embedding: 2-2                              (393,216)\n",
              "│    └─Embedding: 2-3                              (1,536)\n",
              "│    └─LayerNorm: 2-4                              (1,536)\n",
              "│    └─Dropout: 2-5                                --\n",
              "├─ModuleList: 1-2                                  --\n",
              "│    └─BertLayer: 2-6                              --\n",
              "│    │    └─BertAttention: 3-1                     (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-2                  (2,362,368)\n",
              "│    │    └─BertOutput: 3-3                        (2,361,600)\n",
              "│    └─BertLayer: 2-7                              --\n",
              "│    │    └─BertAttention: 3-4                     (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-5                  (2,362,368)\n",
              "│    │    └─BertOutput: 3-6                        (2,361,600)\n",
              "│    └─BertLayer: 2-8                              --\n",
              "│    │    └─BertAttention: 3-7                     (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-8                  (2,362,368)\n",
              "│    │    └─BertOutput: 3-9                        (2,361,600)\n",
              "│    └─BertLayer: 2-9                              --\n",
              "│    │    └─BertAttention: 3-10                    (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-11                 (2,362,368)\n",
              "│    │    └─BertOutput: 3-12                       (2,361,600)\n",
              "│    └─BertLayer: 2-10                             --\n",
              "│    │    └─BertAttention: 3-13                    (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-14                 (2,362,368)\n",
              "│    │    └─BertOutput: 3-15                       (2,361,600)\n",
              "│    └─BertLayer: 2-11                             --\n",
              "│    │    └─BertAttention: 3-16                    (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-17                 (2,362,368)\n",
              "│    │    └─BertOutput: 3-18                       (2,361,600)\n",
              "│    └─BertLayer: 2-12                             --\n",
              "│    │    └─BertAttention: 3-19                    (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-20                 (2,362,368)\n",
              "│    │    └─BertOutput: 3-21                       (2,361,600)\n",
              "│    └─BertLayer: 2-13                             --\n",
              "│    │    └─BertAttention: 3-22                    (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-23                 (2,362,368)\n",
              "│    │    └─BertOutput: 3-24                       (2,361,600)\n",
              "│    └─BertLayer: 2-14                             --\n",
              "│    │    └─BertAttention: 3-25                    (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-26                 (2,362,368)\n",
              "│    │    └─BertOutput: 3-27                       (2,361,600)\n",
              "│    └─BertLayer: 2-15                             --\n",
              "│    │    └─BertAttention: 3-28                    (2,363,904)\n",
              "│    │    └─BertIntermediate: 3-29                 (2,362,368)\n",
              "│    │    └─BertOutput: 3-30                       (2,361,600)\n",
              "├─Dropout: 1-3                                     --\n",
              "├─Flatten: 1-4                                     --\n",
              "├─Linear: 1-5                                      196,864\n",
              "├─Linear: 1-6                                      257\n",
              "├─Linear: 1-7                                      513\n",
              "├─Sigmoid: 1-8                                     --\n",
              "===========================================================================\n",
              "Total params: 94,913,538\n",
              "Trainable params: 197,634\n",
              "Non-trainable params: 94,715,904\n",
              "==========================================================================="
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary( get_custom_bert_model(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d27350ee-fca8-4e35-bfd2-3614e3df7e0e",
      "metadata": {
        "id": "d27350ee-fca8-4e35-bfd2-3614e3df7e0e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c34cc6d0ecb54fcaa768fa965a41ae90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d8f80487e244e34973a7277a76fa84c",
              "IPY_MODEL_e43a335e914a45a1abb80165c0390bcc",
              "IPY_MODEL_0b03169a08334b42ba0faabfc4e1788a"
            ],
            "layout": "IPY_MODEL_4fffe7551f1e40e28bb4682aa702df64"
          }
        },
        "0d8f80487e244e34973a7277a76fa84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fec4aa75d574dff99ad471d44a1f026",
            "placeholder": "​",
            "style": "IPY_MODEL_d200a1f539944c25a09b6687773b9e13",
            "value": "config.json: 100%"
          }
        },
        "e43a335e914a45a1abb80165c0390bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3d510a9fcf34a16a3215a0b6e8b2d2f",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61edd6575d2c40a0802a67b7b2ff9e4b",
            "value": 570
          }
        },
        "0b03169a08334b42ba0faabfc4e1788a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc546c1f05e5456091587903ede5ee34",
            "placeholder": "​",
            "style": "IPY_MODEL_6153c69fe93d4621b0762cd538f1d9bc",
            "value": " 570/570 [00:00&lt;00:00, 5.27kB/s]"
          }
        },
        "4fffe7551f1e40e28bb4682aa702df64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fec4aa75d574dff99ad471d44a1f026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d200a1f539944c25a09b6687773b9e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3d510a9fcf34a16a3215a0b6e8b2d2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61edd6575d2c40a0802a67b7b2ff9e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc546c1f05e5456091587903ede5ee34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6153c69fe93d4621b0762cd538f1d9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f9fb3289d2b46d984d78bbf4840333c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43dc7aed2c6d48aa87567b14db9800e8",
              "IPY_MODEL_6fd658a282a84394a5c57cd904dac2cb",
              "IPY_MODEL_ab7dec18a21146b1bc6f8d608ccbc8b2"
            ],
            "layout": "IPY_MODEL_7d2d2853d5754cfdbfc5958e8f93bd55"
          }
        },
        "43dc7aed2c6d48aa87567b14db9800e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfba79af3c8e4a1388d7158e776060fd",
            "placeholder": "​",
            "style": "IPY_MODEL_307fa19c980e4843a685d0882cc1499d",
            "value": "model.safetensors: 100%"
          }
        },
        "6fd658a282a84394a5c57cd904dac2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aaaeca490e744d79c8e50f320e16220",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47ce46e41422457698aaf8b060cc0c06",
            "value": 440449768
          }
        },
        "ab7dec18a21146b1bc6f8d608ccbc8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b43985336c8c4097b6617f3bd08e84ed",
            "placeholder": "​",
            "style": "IPY_MODEL_04d3af5cb32740b7b6e3d4eb3e64f9fa",
            "value": " 440M/440M [00:05&lt;00:00, 109MB/s]"
          }
        },
        "7d2d2853d5754cfdbfc5958e8f93bd55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfba79af3c8e4a1388d7158e776060fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "307fa19c980e4843a685d0882cc1499d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aaaeca490e744d79c8e50f320e16220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47ce46e41422457698aaf8b060cc0c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b43985336c8c4097b6617f3bd08e84ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d3af5cb32740b7b6e3d4eb3e64f9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a39665c405c4f1a91fa53e1d15012c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26db57945c1c4ba8adbc0d397409ecca",
              "IPY_MODEL_677fa7f8ee4c48569450d93dd18e2692",
              "IPY_MODEL_1cf065cc26ee4d4bbec398d9da191c61"
            ],
            "layout": "IPY_MODEL_1dfd903bcde34aa58e3693e9c0d601ec"
          }
        },
        "26db57945c1c4ba8adbc0d397409ecca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f9911c8bf6a4145b5dbd511d57c0258",
            "placeholder": "​",
            "style": "IPY_MODEL_ebd1a5396ec74419a4a74b93ff7e4f98",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "677fa7f8ee4c48569450d93dd18e2692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e746f9bab8e6484193ece0f8d431660e",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_440e232b382f456587540e812d0cc1e8",
            "value": 48
          }
        },
        "1cf065cc26ee4d4bbec398d9da191c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fb1c703cebd4f769543be9356f8978f",
            "placeholder": "​",
            "style": "IPY_MODEL_87c191c6a6a045ee9deef87390083954",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.80kB/s]"
          }
        },
        "1dfd903bcde34aa58e3693e9c0d601ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f9911c8bf6a4145b5dbd511d57c0258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebd1a5396ec74419a4a74b93ff7e4f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e746f9bab8e6484193ece0f8d431660e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "440e232b382f456587540e812d0cc1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fb1c703cebd4f769543be9356f8978f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87c191c6a6a045ee9deef87390083954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17a045610272481fb0240283bf7e570d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_810dc92e12d14a9a8399578f51bba260",
              "IPY_MODEL_132537527d7245b884343a724ad49c69",
              "IPY_MODEL_f02dc5515dbe44e58a124e3910290b95"
            ],
            "layout": "IPY_MODEL_1ca7180c5ce94646952d3d1a1dff5079"
          }
        },
        "810dc92e12d14a9a8399578f51bba260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b9ebfed15254f1aacc686cf5d678334",
            "placeholder": "​",
            "style": "IPY_MODEL_8404f9c129d54c1581b0135fbf1c0099",
            "value": "vocab.txt: 100%"
          }
        },
        "132537527d7245b884343a724ad49c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_569c9b9ec24d4a90bdcd024df49af985",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9eaff47ccf144e4987ba2fd4a5a946a7",
            "value": 231508
          }
        },
        "f02dc5515dbe44e58a124e3910290b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4198feeea9a41aca81444efcea7f31c",
            "placeholder": "​",
            "style": "IPY_MODEL_86eb1a8901aa4844918266ba956fff9b",
            "value": " 232k/232k [00:00&lt;00:00, 2.19MB/s]"
          }
        },
        "1ca7180c5ce94646952d3d1a1dff5079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b9ebfed15254f1aacc686cf5d678334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8404f9c129d54c1581b0135fbf1c0099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "569c9b9ec24d4a90bdcd024df49af985": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eaff47ccf144e4987ba2fd4a5a946a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4198feeea9a41aca81444efcea7f31c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86eb1a8901aa4844918266ba956fff9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85dff2268762428ea8c5c66ed84c02de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f63515fba5424c79a1549c1f14e41a9d",
              "IPY_MODEL_d239ec8ed6ae473fbaead8e0dc3edde3",
              "IPY_MODEL_38fd204428254c609671dd1422037bdf"
            ],
            "layout": "IPY_MODEL_3daea2f3157649ffbc5fb6352a443e1e"
          }
        },
        "f63515fba5424c79a1549c1f14e41a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aee9590e58a0474d9dfd2a0169b5621d",
            "placeholder": "​",
            "style": "IPY_MODEL_82f0a1d8502841e8a6d453fe0601b419",
            "value": "tokenizer.json: 100%"
          }
        },
        "d239ec8ed6ae473fbaead8e0dc3edde3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f63efe2b2469465eade49a15b5c7bf6c",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a5ff22b8f724ae4bcdf5b74fedc26c9",
            "value": 466062
          }
        },
        "38fd204428254c609671dd1422037bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c21c1a3e98f458fa234ca77a3e143f8",
            "placeholder": "​",
            "style": "IPY_MODEL_2125b7ba262847beb78269fbab59d807",
            "value": " 466k/466k [00:00&lt;00:00, 8.56MB/s]"
          }
        },
        "3daea2f3157649ffbc5fb6352a443e1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aee9590e58a0474d9dfd2a0169b5621d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82f0a1d8502841e8a6d453fe0601b419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f63efe2b2469465eade49a15b5c7bf6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a5ff22b8f724ae4bcdf5b74fedc26c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c21c1a3e98f458fa234ca77a3e143f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2125b7ba262847beb78269fbab59d807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}