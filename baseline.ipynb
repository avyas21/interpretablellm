{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f343ad35-e195-4859-a3a7-35e4120d1b69",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f343ad35-e195-4859-a3a7-35e4120d1b69",
        "outputId": "861a413e-d24e-476a-8035-ebf2dff0ff0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Collecting numpy==1.26.0\n",
            "  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.19 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.0\n",
            "Requirement already satisfied: tensorflow[and-cuda] in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.26.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.37.1)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.5.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
            "Requirement already satisfied: nvidia-cuda-nvcc-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.3.0.75 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (9.3.0.75)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.3.61 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (11.2.3.61)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.6.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (10.3.6.82)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.3.83 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (11.6.3.83)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.1.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow[and-cuda]) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow[and-cuda]) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow[and-cuda]) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow[and-cuda]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow[and-cuda]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow[and-cuda]) (0.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting comm>=0.1.3 (from ipywidgets)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, jedi, comm, ipywidgets\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.2 ipywidgets-8.1.5 jedi-0.19.2 widgetsnbextension-4.0.13\n",
            "Requirement already satisfied: tf-keras in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tf-keras) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.26.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install numpy==1.26.0\n",
        "!pip install tensorflow[and-cuda]\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install --upgrade ipywidgets\n",
        "!pip install tf-keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2962b9d0-ba93-4ffa-bf14-18aa63fedea6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2962b9d0-ba93-4ffa-bf14-18aa63fedea6",
        "outputId": "bd7a40fb-66da-4ff6-a777-828a13980d3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b82dd9f-e6d6-46ac-9843-ca25199683dc",
      "metadata": {
        "id": "9b82dd9f-e6d6-46ac-9843-ca25199683dc"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c594c372-0387-4956-b9e6-a362de13ab1b",
      "metadata": {
        "id": "c594c372-0387-4956-b9e6-a362de13ab1b"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dcc1073e-f664-4053-a2a0-6a866a8ba2b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcc1073e-f664-4053-a2a0-6a866a8ba2b0",
        "outputId": "d5ea6b1f-165f-4e15-e085-34083f8deae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n",
        "from transformers import BertModel, BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3efd9030-e3ac-4c20-92b5-a82df8b63a4b",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3efd9030-e3ac-4c20-92b5-a82df8b63a4b",
        "outputId": "635f2c76-af5d-4a56-ee63-a2feefaf84c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 8, 768])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the BERT model and tokenizer\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Process a sentence\n",
        "\n",
        "input_text = \"This is a sample sentence.\"\n",
        "\n",
        "encoded_input = tokenizer(input_text, return_tensors=\"pt\")\n",
        "output = model(**encoded_input, output_hidden_states=True)\n",
        "\n",
        "print(output.hidden_states[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd interpretablellm/data\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DhDookCV4cA",
        "outputId": "a49f3bef-4fa1-4d67-ee12-7aa41b39eb40"
      },
      "id": "9DhDookCV4cA",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'interpretablellm/data'\n",
            "/content/interpretablellm/data\n",
            "runs  test_data.csv  train_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from transformers import AutoTokenizer, BertModel\n",
        "import pandas as pd\n",
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self, n):\n",
        "          super(CustomBERTModel, self).__init__()\n",
        "          self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "          ### New layers:\n",
        "          self.flatten = nn.Flatten()\n",
        "          self.linear1 = nn.Linear(768, 256)\n",
        "          self.linear2 = nn.Linear(256, 1)\n",
        "          self.linear3 = nn.Linear(512, 1)\n",
        "          self.sigmoid = nn.Sigmoid()\n",
        "          self.n = n\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "          embedding_output = self.bert.embeddings(input_ids)\n",
        "          encoder_outputs = embedding_output\n",
        "          for i, layer_module in enumerate(self.bert.encoder.layer):\n",
        "              encoder_outputs = layer_module(encoder_outputs)[0]\n",
        "              if i + 1 == self.n:\n",
        "                  break\n",
        "\n",
        "          linear1_output = self.linear1(encoder_outputs)\n",
        "          print(linear1_output.shape)\n",
        "          linear2_output = self.linear2(linear1_output)\n",
        "          print(linear2_output.shape)\n",
        "          flattened_output = self.flatten(linear2_output)\n",
        "          print(flattened_output.shape)\n",
        "          linear3_output = self.linear3(flattened_output)\n",
        "          print(linear3_output.shape)\n",
        "          sigmoid_output = self.sigmoid(linear3_output)\n",
        "          print(sigmoid_output.shape)\n",
        "\n",
        "\n",
        "          # sequence_output, pooled_output = self.bert(\n",
        "          #      ids,\n",
        "          #      attention_mask=mask)\n",
        "\n",
        "          # # sequence_output has the following shape: (batch_size, sequence_length, 768)\n",
        "\n",
        "\n",
        "          return sigmoid_output\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "# model = CustomBERTModel() # You can pass the parameters if required to have more flexible model\n",
        "# model.to(torch.device(\"cpu\")) ## can be gpu\n",
        "# criterion = nn.CrossEntropyLoss() ## If required define your own criterion\n",
        "# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "\n",
        "train = pd.read_csv(\"train_data.csv\")"
      ],
      "metadata": {
        "id": "hs9tJr6xUte3"
      },
      "id": "hs9tJr6xUte3",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['Sentiment'] = train['Sentiment'].replace({'Positive': 1, 'Negative': 0})\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "lX-6ZSN-Wb7f",
        "outputId": "f35a3f4f-ec2b-463f-a24f-5a4ca351d225"
      },
      "id": "lX-6ZSN-Wb7f",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-d786a8a05c96>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  train['Sentiment'] = train['Sentiment'].replace({'Positive': 1, 'Negative': 0})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Review  Sentiment\n",
              "0     Updated: after first book arrived very damaged...          1\n",
              "1     Missing the sketch pad. Even worse I realized ...          0\n",
              "2     Every page has a crease running the entire len...          0\n",
              "3     This was my 6th copy!  All 5 of my kids had th...          1\n",
              "4     Wonderful book but not crazy about using the w...          1\n",
              "...                                                 ...        ...\n",
              "7995  Weak interpretation of Korean cooking. Not aut...          0\n",
              "7996  If you want to read a book about a 6 month old...          0\n",
              "7997  Activation codes DO NOT WORK. And Esri will no...          0\n",
              "7998  Complete waste of time to read. Read Silent Sp...          0\n",
              "7999  I've read several reading texts and I didn't c...          0\n",
              "\n",
              "[8000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67e62944-3375-4d03-8da0-b0e2432a2b58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Updated: after first book arrived very damaged...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Missing the sketch pad. Even worse I realized ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Every page has a crease running the entire len...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This was my 6th copy!  All 5 of my kids had th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wonderful book but not crazy about using the w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>Weak interpretation of Korean cooking. Not aut...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>If you want to read a book about a 6 month old...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>Activation codes DO NOT WORK. And Esri will no...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>Complete waste of time to read. Read Silent Sp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>I've read several reading texts and I didn't c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67e62944-3375-4d03-8da0-b0e2432a2b58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-67e62944-3375-4d03-8da0-b0e2432a2b58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-67e62944-3375-4d03-8da0-b0e2432a2b58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-de2eba34-b23d-4f32-9bd6-16718b321572\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de2eba34-b23d-4f32-9bd6-16718b321572')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-de2eba34-b23d-4f32-9bd6-16718b321572 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1bb06135-bf40-4443-ad86-d02a41fe2475\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1bb06135-bf40-4443-ad86-d02a41fe2475 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 8000,\n  \"fields\": [\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7850,\n        \"samples\": [\n          \"Oooh so good and easy.  We love curries at home, especially butter chicken curry and lamb korma.  This book has distilled the essential spices you need, and into the pot [may include a marinade step].  Voila. Delicious food on the table.  We tried a couple of the Indian subcontinent section: thumbs up for yummy curries.  The plus part of the book  is that there are sections covering Thailand and Asia, Middle East and Africa, and Caribbean and Latin America. We are in curry heaven, we tried spicy chicken curry [Dara wat] from the Middle East section - delicious.  There is a section with spice mixes you will need to make some of the curries.  So worth it.  Now that autumn and colder months are rolling in, these curries will be a stab;e.\",\n          \"I really enjoyed Veronica Rossi\\u2019s Under the Never Sky trilogy, so I was excited to check out the start to her new series, Riders. If you\\u2019ve read her first series, don\\u2019t expect RIDERS to be anything like it. They are 100% different, which was both good and bad for me.<br /><br />RIDERS takes a new spin on the Four Horsemen of the Apocalypse. Here, the horsemen are four teenage boys, all of whom wake up with strange cuffs on their wrists after dying. But their attempts to return to normal life don\\u2019t work. Gideon, our narrator, realizes he can make others feel anger. Days after his death and awakening, he\\u2019s off on a roadtrip with Daryn, a mysterious young woman who insists she knows what\\u2019s going on, but can\\u2019t tell him anything yet. Oh, and can they drive around the U.S. and pick up the other horsemen? Because they have to be together to save the world.<br /><br />Most of RIDERS is told in Gideon\\u2019s flashbacks. At the start of the book, he\\u2019s being interrogated by unknown parties after some unknown big stuff went down. I was very meh on the first 70% or so of the book. There didn\\u2019t seem to be much of a plot. It was somewhat boring, having Gideon recount the past few weeks, his painful attraction to Daryn, and so on. I wasn\\u2019t a fan of the blunt, disjointed writing style, although I did really like Gideon\\u2019s voice. He read and felt like a real guy, not wish fulfilment.<br /><br />The last 30% of the book is where I liked RIDERS a whole lot more. I was tempted to put it down before I reached that point, but here is one time where continuing was actually a good thing. Finally there was action (and a *lot* of it). I liked seeing the guys and their horses interact, the guys bond, and also learning more about the Kindred and the big secret.<br /><br />For me, RIDERS was just okay. I was hoping for more, given how much I enjoyed Under the Never Sky. I liked the end of RIDERS, but I shouldn\\u2019t have been meh on so much of the book to get to that end.\",\n          \"Okay, so I have to be honest here. The Retribution of Mara Dyer felt really disappointing in comparison to the other two novels. If you haven't read the first two and are planning to read them, you might want to stop here because there will be spoilers for things that happened in the first two books (but no spoilers for book 3!).<br /><br />Just like the second book, the third installment picks up right where the last one left off. Mara knows now that the powers she has are because of genetic markers and experiments that were done on a number of people, including Noah, Jude, and Jamie. Dr. Kells was in on the entire thing, which is why she was forced to stay at the Horizons center. In the last book, we find Mara trying to escape from Horizons and Kells, and understand how their powers came to be, and why they were chosen.<br /><br />Mostly, I felt bored. I felt like I should be really excited to see the conclusion of the story, but a lot of the time I wanted to put the book down and walk away because it was so tediously boring. I used to love Mara as the main character, but I didn't like her in 97% of this book. I know she'd been through a lot, which naturally will change someone a little bit, but I felt like she wasn't at all the girl she started out to be, and that didn't work for me. She felt vindictive, petty, and self centered, which is not at all the girl she started out being.<br /><br />I also felt like there were a lot of things that felt unresolved and that there were questions that weren't answered. I get that not all of them were important, but I felt like the only stories that got wrapped up were Mara's, Jamie's, Noah's, and Daniel's. What happened to Noah's dad and Mara's family? What about Stella? And the Professor? NO CLOSURE. I could seriously list 5 more things that we didn't get closure on, but I shall refrain. Like, I literally feel like the closure that existed was to wrap up Mara and Noah's romance, and without giving anything away, it felt so cheesy.<br /><br />I can't say I loved this book. I'm honestly not sure if I even liked it. A great big MEH is what it gets from me\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = []\n",
        "preds = []\n",
        "for idx, row in train.iterrows():\n",
        "  try:\n",
        "    input_text = row['Review']\n",
        "    #encoded_input = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    #output = model(**encoded_input, output_hidden_states=True)\n",
        "    # outputs.append(output.hidden_states[0])\n",
        "    # outputs.append(encoded_input)\n",
        "    outputs.append(input_text)\n",
        "    preds.append(1 if row['Sentiment'] == 'Positive' else 0)\n",
        "  except:\n",
        "    continue\n",
        "  if idx > 100:\n",
        "    break"
      ],
      "metadata": {
        "id": "ZuLuCEEqWxpF"
      },
      "id": "ZuLuCEEqWxpF",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_len = max([out.shape[1] for out in outputs])  # Find the longest sequence\n",
        "\n",
        "# # Pad all outputs to the same length\n",
        "# padded_outputs = []\n",
        "# for out in outputs:\n",
        "#     padding_size = max_len - out.shape[1]\n",
        "#     # Apply padding to the sequence along the second dimension (sequence_length)\n",
        "#     padded_out = torch.nn.functional.pad(out, (0, 0, 0, padding_size))  # Pads the sequence length dimension\n",
        "#     padded_outputs.append(padded_out)\n",
        "# for i in range (len(padded_outputs)):\n",
        "#   print(padded_outputs[i].shape)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKnOG4UJe1Ml",
        "outputId": "5a50ae0b-e68c-46e2-cc2d-7355bc6eb765"
      },
      "id": "DKnOG4UJe1Ml",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n",
            "torch.Size([1, 261, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label)\n",
        "        }\n",
        "\n",
        "dataset = TextDataset(outputs, preds, tokenizer, 512)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Iterate through the dataloader\n",
        "for batch in dataloader:\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    labels = batch['label']\n",
        "\n",
        "    # Use the data for training/evaluation\n",
        "    print(\"Input IDs shape:\", input_ids.shape)\n",
        "    print(\"Attention Mask shape:\", attention_mask.shape)\n",
        "    print(\"Labels:\", labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "485XykGLie_x",
        "outputId": "37bd8dae-b074-4a56-cce4-a473be501f9a"
      },
      "id": "485XykGLie_x",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs shape: torch.Size([16, 512])\n",
            "Attention Mask shape: torch.Size([16, 512])\n",
            "Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Input IDs shape: torch.Size([16, 512])\n",
            "Attention Mask shape: torch.Size([16, 512])\n",
            "Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Input IDs shape: torch.Size([16, 512])\n",
            "Attention Mask shape: torch.Size([16, 512])\n",
            "Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Input IDs shape: torch.Size([16, 512])\n",
            "Attention Mask shape: torch.Size([16, 512])\n",
            "Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Input IDs shape: torch.Size([16, 512])\n",
            "Attention Mask shape: torch.Size([16, 512])\n",
            "Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Input IDs shape: torch.Size([16, 512])\n",
            "Attention Mask shape: torch.Size([16, 512])\n",
            "Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Input IDs shape: torch.Size([6, 512])\n",
            "Attention Mask shape: torch.Size([6, 512])\n",
            "Labels: tensor([0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #X_tensor = torch.tensor(outputs)\n",
        "# X_tensor = torch.cat(padded_outputs, dim=0)\n",
        "# Y_tensor = torch.from_numpy(np.array(preds)).float()\n",
        "# dataset = torch.utils.data.TensorDataset(X_tensor, Y_tensor)\n",
        "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "L1nK41eEaqnh"
      },
      "id": "L1nK41eEaqnh",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_custom = CustomBERTModel(1) # You can pass the parameters if required to have more flexible model\n",
        "model_custom.to(torch.device(\"cpu\")) ## can be gpu\n",
        "loss_fn = nn.BCELoss() ## If required define your own criterion\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model_custom.parameters()))"
      ],
      "metadata": {
        "id": "ofKae1ImZPqL"
      },
      "id": "ofKae1ImZPqL",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(dataloader):\n",
        "        # Every data instance is an input + label pair\n",
        "        print(data)\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(dataloader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ],
      "metadata": {
        "id": "L53zFoGWaT0q"
      },
      "id": "L53zFoGWaT0q",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-italian-xxl-cased\")\n",
        "model = CustomBERTModel(1) # You can pass the parameters if required to have more flexible model\n",
        "model.to(torch.device(\"cpu\")) ## can be gpu\n",
        "criterion = nn.BCELoss() ## If required define your own criterion\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "\n",
        "epochs = 1\n",
        "for epoch in range(epochs):\n",
        "    for batch in dataloader: ## If you have a DataLoader()  object to get the data.\n",
        "        print(batch)\n",
        "        #encoding = batch[0]\n",
        "        targets = np.array(batch['label']) ## assuming that data loader returns a tuple of data and its targets\n",
        "        targets = torch.tensor(np.expand_dims(targets,axis=1)).float()\n",
        "        print(targets.shape)\n",
        "        optimizer.zero_grad()\n",
        "        #encoding = tokenizer.batch_encode_plus(data, return_tensors='pt', padding=True, truncation=True,max_length=50, add_special_tokens = True)\n",
        "        input_ids = batch['input_ids']\n",
        "        #print(input_ids.shape)\n",
        "        attention_mask = batch['attention_mask']\n",
        "        #print(attention_mask.shape)\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        #outputs = F.log_softmax(outputs, dim=1)\n",
        "        #print(outputs.shape)\n",
        "        loss = criterion(outputs, targets)\n",
        "        print(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9hGOXhcfrs4",
        "outputId": "a23c72ff-3f48-4c86-df9a-92a45dd51550"
      },
      "id": "q9hGOXhcfrs4",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  2023,  1037,  ...,     0,     0,     0],\n",
            "        [  101,  1997,  2607,  ...,     0,     0,     0],\n",
            "        [  101,  2296,  3931,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 10140,  2338,  ...,     0,     0,     0],\n",
            "        [  101,  2293,  2035,  ...,     0,     0,     0],\n",
            "        [  101,  1045,  5959,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'label': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n",
            "torch.Size([16, 1])\n",
            "torch.Size([16, 512, 256])\n",
            "torch.Size([16, 512, 1])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 1])\n",
            "torch.Size([16, 1])\n",
            "tensor(0.6831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "{'input_ids': tensor([[  101,  1045,  2031,  ...,     0,     0,     0],\n",
            "        [  101,  2307,  4979,  ...,     0,     0,     0],\n",
            "        [  101,  2026,  2048,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  2288,  2023,  ...,     0,     0,     0],\n",
            "        [  101,  2023,  2003,  ...,     0,     0,     0],\n",
            "        [  101,  2200, 10140,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'label': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n",
            "torch.Size([16, 1])\n",
            "torch.Size([16, 512, 256])\n",
            "torch.Size([16, 512, 1])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 1])\n",
            "torch.Size([16, 1])\n",
            "tensor(0.1033, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "{'input_ids': tensor([[ 101, 2026, 1015,  ...,    0,    0,    0],\n",
            "        [ 101, 2023, 2003,  ...,    0,    0,    0],\n",
            "        [ 101, 2293, 2122,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 101, 2307, 2338,  ...,    0,    0,    0],\n",
            "        [ 101, 2178, 2307,  ...,    0,    0,    0],\n",
            "        [ 101, 1045, 2342,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'label': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n",
            "torch.Size([16, 1])\n",
            "torch.Size([16, 512, 256])\n",
            "torch.Size([16, 512, 1])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 1])\n",
            "torch.Size([16, 1])\n",
            "tensor(0.0004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "{'input_ids': tensor([[ 101, 2057, 2293,  ...,    0,    0,    0],\n",
            "        [ 101, 3369, 1999,  ...,    0,    0,    0],\n",
            "        [ 101, 2004, 2007,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 101, 2293, 2009,  ...,    0,    0,    0],\n",
            "        [ 101, 2307, 3439,  ...,    0,    0,    0],\n",
            "        [ 101, 2023, 2003,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'label': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n",
            "torch.Size([16, 1])\n",
            "torch.Size([16, 512, 256])\n",
            "torch.Size([16, 512, 1])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 1])\n",
            "torch.Size([16, 1])\n",
            "tensor(4.6269e-05, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "{'input_ids': tensor([[  101,  2002,  1005,  ...,     0,     0,     0],\n",
            "        [  101, 23677,  2338,  ...,     0,     0,     0],\n",
            "        [  101,  2043,  1045,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  2023,  2003,  ...,     0,     0,     0],\n",
            "        [  101,  1045,  4149,  ...,     0,     0,     0],\n",
            "        [  101,  1045,  2921,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'label': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n",
            "torch.Size([16, 1])\n",
            "torch.Size([16, 512, 256])\n",
            "torch.Size([16, 512, 1])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 1])\n",
            "torch.Size([16, 1])\n",
            "tensor(2.4251e-05, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "{'input_ids': tensor([[  101,  1037,  2092,  ...,     0,     0,     0],\n",
            "        [  101,  1045,  2428,  ...,     0,     0,     0],\n",
            "        [  101,  2183,  2000,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  2025,  2005,  ...,     0,     0,     0],\n",
            "        [  101,  1996, 13425,  ...,     0,     0,     0],\n",
            "        [  101,  1037,  9608,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'label': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n",
            "torch.Size([16, 1])\n",
            "torch.Size([16, 512, 256])\n",
            "torch.Size([16, 512, 1])\n",
            "torch.Size([16, 512])\n",
            "torch.Size([16, 1])\n",
            "torch.Size([16, 1])\n",
            "tensor(4.7680e-05, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "{'input_ids': tensor([[  101,  2023,  2003,  ...,     0,     0,     0],\n",
            "        [  101,  5959,  2300,  ...,     0,     0,     0],\n",
            "        [  101,  6919,  2135,  ...,     0,     0,     0],\n",
            "        [  101, 10124,  2224,  ...,     0,     0,     0],\n",
            "        [  101,  2054,  1037,  ...,     0,     0,     0],\n",
            "        [  101,  1045,  2228,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'label': tensor([0, 0, 0, 0, 0, 0])}\n",
            "torch.Size([6, 1])\n",
            "torch.Size([6, 512, 256])\n",
            "torch.Size([6, 512, 1])\n",
            "torch.Size([6, 512])\n",
            "torch.Size([6, 1])\n",
            "torch.Size([6, 1])\n",
            "tensor(0.0001, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVWM7p9W7FkT",
        "outputId": "b634ef79-ffba-46d9-d173-cf325c445dd6"
      },
      "id": "qVWM7p9W7FkT",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0001, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a4fa17e8-816d-4eab-af63-bd259bd4c5a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4fa17e8-816d-4eab-af63-bd259bd4c5a1",
        "outputId": "32a4d2e5-a714-4814-ce69-9c8946ee7161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.09747565537691116,\n",
              "  'token': 10533,\n",
              "  'token_str': 'carpenter',\n",
              "  'sequence': 'the man worked as a carpenter.'},\n",
              " {'score': 0.052383214235305786,\n",
              "  'token': 15610,\n",
              "  'token_str': 'waiter',\n",
              "  'sequence': 'the man worked as a waiter.'},\n",
              " {'score': 0.04962708428502083,\n",
              "  'token': 13362,\n",
              "  'token_str': 'barber',\n",
              "  'sequence': 'the man worked as a barber.'},\n",
              " {'score': 0.037886086851358414,\n",
              "  'token': 15893,\n",
              "  'token_str': 'mechanic',\n",
              "  'sequence': 'the man worked as a mechanic.'},\n",
              " {'score': 0.037680841982364655,\n",
              "  'token': 18968,\n",
              "  'token_str': 'salesman',\n",
              "  'sequence': 'the man worked as a salesman.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
        "unmasker(\"The man worked as a [MASK].\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b02b0e9a-f9a6-40a3-a6f5-5cfbbd94745c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b02b0e9a-f9a6-40a3-a6f5-5cfbbd94745c",
        "outputId": "34a9a31c-9c9c-4c12-eae8-330314fe7677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'interpretablellm' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/avyas21/interpretablellm.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_review(review):\n",
        "  prompt = \"Return whether the sentiment is positive or negative.\"\n",
        "  unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
        "  return unmasker(\"Review: \" + review + \"This review was [MASK]\")"
      ],
      "metadata": {
        "id": "t_0VrFZpMp3h"
      },
      "id": "t_0VrFZpMp3h",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_review(\"A well thought out book that teaches my kids manners and how to be polite!!! Could it get any better?!? There are 30 beautiful designed and illustrated pages in the continuing story of My Travel Friends. This series just gets better and better! The interactive app really brings the book to life with voices and songs!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVxTL36fNBTe",
        "outputId": "09d659f5-43b9-4d5d-f75a-2c42b227a561"
      },
      "id": "CVxTL36fNBTe",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.4765911102294922,\n",
              "  'token': 1012,\n",
              "  'token_str': '.',\n",
              "  'sequence': 'review : a well thought out book that teaches my kids manners and how to be polite!!! could it get any better?!? there are 30 beautiful designed and illustrated pages in the continuing story of my travel friends. this series just gets better and better! the interactive app really brings the book to life with voices and songs! this review was.'},\n",
              " {'score': 0.2635924816131592,\n",
              "  'token': 1025,\n",
              "  'token_str': ';',\n",
              "  'sequence': 'review : a well thought out book that teaches my kids manners and how to be polite!!! could it get any better?!? there are 30 beautiful designed and illustrated pages in the continuing story of my travel friends. this series just gets better and better! the interactive app really brings the book to life with voices and songs! this review was ;'},\n",
              " {'score': 0.1289989948272705,\n",
              "  'token': 1029,\n",
              "  'token_str': '?',\n",
              "  'sequence': 'review : a well thought out book that teaches my kids manners and how to be polite!!! could it get any better?!? there are 30 beautiful designed and illustrated pages in the continuing story of my travel friends. this series just gets better and better! the interactive app really brings the book to life with voices and songs! this review was?'},\n",
              " {'score': 0.0976438820362091,\n",
              "  'token': 999,\n",
              "  'token_str': '!',\n",
              "  'sequence': 'review : a well thought out book that teaches my kids manners and how to be polite!!! could it get any better?!? there are 30 beautiful designed and illustrated pages in the continuing story of my travel friends. this series just gets better and better! the interactive app really brings the book to life with voices and songs! this review was!'},\n",
              " {'score': 0.030116455629467964,\n",
              "  'token': 1064,\n",
              "  'token_str': '|',\n",
              "  'sequence': 'review : a well thought out book that teaches my kids manners and how to be polite!!! could it get any better?!? there are 30 beautiful designed and illustrated pages in the continuing story of my travel friends. this series just gets better and better! the interactive app really brings the book to life with voices and songs! this review was |'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertModel"
      ],
      "metadata": {
        "id": "qyWMJM6bPTd3"
      },
      "id": "qyWMJM6bPTd3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}